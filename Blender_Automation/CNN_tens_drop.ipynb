{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 16 * 16)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "# Set up the data directories\n",
    "data_dir = 'Test_Images'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "# Define a function to get the labels from the image filenames\n",
    "def get_label(filename):\n",
    "    match = re.search(r'\\d+\\.?\\d*', filename)\n",
    "    if match:\n",
    "        return float(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Define a list to store the image filenames and labels\n",
    "train_data = []\n",
    "\n",
    "# Iterate over the training images and add them to the list\n",
    "for filename in os.listdir(train_dir):\n",
    "    label = get_label(filename)\n",
    "    if label is not None:\n",
    "        train_data.append([os.path.join(train_dir, filename), label])\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "train_df = pd.DataFrame(train_data, columns=['filename', 'label'])\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "train_df.to_csv(os.path.join(data_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1080, 1920]) 100.0\n"
     ]
    }
   ],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = self._load_data(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_data(self, csv_file):\n",
    "    # Load and preprocess data from the CSV file\n",
    "    # Example: Assuming the CSV file has two columns representing image paths and labels\n",
    "        data = []\n",
    "        with open(csv_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines[1:]:  # Skip the header row\n",
    "                # Split the line by comma or any other appropriate delimiter\n",
    "                image_path, label = line.strip().split(',')\n",
    "                data.append((image_path, float(label)))  # Parse the label as float\n",
    "        return data\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "csv_file = 'Test_Images/train.csv'  # Replace with the path to your CSV file\n",
    "image_folder = 'Test_Images/train'  # Replace with the path to your image folder\n",
    "dataset = CustomImageDataset(csv_file, image_folder, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# Access individual samples\n",
    "image, label = dataset[0]\n",
    "print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "csv_file = 'Test_Images/train.csv'  # Replace with the path to your CSV file\n",
    "image_folder = 'Test_Images/train'  # Replace with the path to your image folder\n",
    "\n",
    "dataset = CustomImageDataset(csv_file, image_folder, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "model = CNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Validation Loss: 156.253153\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Validation Loss: 156.253153\n",
      "Epoch 2 completed.\n",
      "Epoch 3 - Validation Loss: 156.253153\n",
      "Epoch 3 completed.\n",
      "Epoch 4 - Validation Loss: 156.253153\n",
      "Epoch 4 completed.\n",
      "Epoch 5 - Validation Loss: 156.253153\n",
      "Epoch 5 completed.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()  # Set the model to training mode\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_samples = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_samples += inputs.size(0)\n",
    "        \n",
    "        average_val_loss = val_loss / val_samples\n",
    "        print('Epoch %d - Validation Loss: %.6f' % (epoch + 1, average_val_loss))\n",
    "        \n",
    "    print('Epoch %d completed.' % (epoch + 1))\n",
    "\n",
    "torch.save(model, 'trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('trained_model')  # Replace 'trained_model.pth' with the path to your trained model file\n",
    "\n",
    "# Load and preprocess the input image\n",
    "input_image = Image.open('Test_Images\\drop_s100_v15_r0.5_str6_pos1.png_edged.png')  # Replace 'input_image.jpg' with the path to your input image file\n",
    "input_image = input_image.convert('RGB')\n",
    "input_tensor = transform(input_image)\n",
    "\n",
    "# input_tensor = torchvision.transforms.ToTensor()(input_image).unsqueeze(0)  # Preprocess the image and add a batch dimension\n",
    "input_tensor.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 87.73915100097656\n"
     ]
    }
   ],
   "source": [
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Convert the output to a readable format\n",
    "predicted_value = output.item()\n",
    "\n",
    "# Print the predicted value\n",
    "print('Predicted value:', predicted_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
