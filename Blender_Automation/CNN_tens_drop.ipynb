{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the CNN model\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.fc1 = nn.Linear(32 * 16 * 16, 256)\n",
    "#         self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 32 * 16 * 16)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.fc3 = nn.Linear(256, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))\n",
    "#         x = self.pool(torch.relu(self.conv3(x)))\n",
    "#         x = x.view(-1, 64 * 8 * 8)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.fc3 = nn.Linear(256, 128)\n",
    "#         self.fc4 = nn.Linear(128, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))\n",
    "#         x = self.pool(torch.relu(self.conv3(x)))\n",
    "#         x = self.pool(torch.relu(self.conv4(x)))\n",
    "#         x = x.view(-1, 128 * 4 * 4)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = torch.relu(self.fc3(x))\n",
    "#         x = self.fc4(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = self.pool(torch.relu(self.conv4(x)))\n",
    "        x = self.pool(torch.relu(self.conv5(x)))\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(1024 * 1 * 1, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = self.pool(torch.relu(self.conv4(x)))\n",
    "        x = self.pool(torch.relu(self.conv5(x)))\n",
    "        x = self.pool(torch.relu(self.conv6(x)))\n",
    "        x = x.view(-1, 1024 * 1 * 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "# Set up the data directories\n",
    "data_dir = 'Test_Images'\n",
    "train_dir = os.path.join(data_dir, 'Train')\n",
    "\n",
    "# Define a function to get the labels from the image filenames\n",
    "def get_label(filename):\n",
    "    match = re.search(r'\\d+\\.?\\d*', filename)\n",
    "    if match:\n",
    "        return float(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Define a list to store the image filenames and labels\n",
    "train_data = []\n",
    "\n",
    "# Iterate over the training images and add them to the list\n",
    "for filename in os.listdir(train_dir):\n",
    "    label = get_label(filename)\n",
    "    if label is not None:\n",
    "        train_data.append([os.path.join(train_dir, filename), label])\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "train_df = pd.DataFrame(train_data, columns=['filename', 'label'])\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "train_df.to_csv(os.path.join(data_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = self._load_data(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_data(self, csv_file):\n",
    "    # Load and preprocess data from the CSV file\n",
    "    # Example: Assuming the CSV file has two columns representing image paths and labels\n",
    "        data = []\n",
    "        with open(csv_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines[1:]:  # Skip the header row\n",
    "                # Split the line by comma or any other appropriate delimiter\n",
    "                image_path, label = line.strip().split(',')\n",
    "                data.append((image_path, float(label)))  # Parse the label as float\n",
    "        return data\n",
    "\n",
    "# # Access individual samples\n",
    "# image, label = dataset[0]\n",
    "# print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "# psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# # loop through images\n",
    "# # for inputs in train_data:#DataLoader(train_data, batch_size=batch_size, shuffle=True):\n",
    "# for i, (images, labels) in enumerate(train_loader):\n",
    "#     psum    += images.sum(axis        = [0, 2, 3])\n",
    "#     psum_sq += (images ** 2).sum(axis = [0, 2, 3])\n",
    "    \n",
    "\n",
    "# # Final Calculation\n",
    "# # pixel count\n",
    "# image_size = 256\n",
    "# count = 870 * image_size * image_size\n",
    "\n",
    "# # mean and std\n",
    "# total_mean = psum / count\n",
    "# total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "# total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# # output\n",
    "# print('mean: '  + str(total_mean))\n",
    "# print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Image.open('Test_Images\\Train\\drop_s41_v5_r0.5_str6_pos0_cam150.png')  # Replace 'input_image.jpg' with the path to your input image file\n",
    "transform = ToTensor()\n",
    "tensor = transform(input_image)\n",
    "# Calculate mean and standard deviation\n",
    "mean = torch.mean(tensor)\n",
    "std = torch.std(tensor)\n",
    "\n",
    "# Normalize the data\n",
    "normalizer = Normalize(mean=[mean.item(), mean.item(), mean.item()], std=[std.item(), std.item(), std.item()])\n",
    "# Set up the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean= [0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])               # Need to be adjusted, acording to dataset\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "csv_file = 'Test_Images/train.csv'  # Replace with the path to your CSV file\n",
    "image_folder = 'Test_Images/train'  # Replace with the path to your image folder\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "dataset = CustomImageDataset(csv_file, image_folder, transform=transform)\n",
    "val_split = 0.2  # Percentage of data for validation\n",
    "val_size = int(val_split * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc6): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "model = CNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-db38bee24037>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml2_lambda\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ml2_regularization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# num_epochs = 30\n",
    "# best_val_loss = float('inf')\n",
    "# patience = 5  # Number of epochs to wait for improvement\n",
    "# counter = 0  # Counter to track the number of epochs without improvement\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "    \n",
    "#     # Training phase\n",
    "#     model.train()\n",
    "#     for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         labels = labels.unsqueeze(1)\n",
    "#         loss = criterion(outputs, labels.float())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "#         if i % 100 == 99:\n",
    "#             print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "#             running_loss = 0.0\n",
    "            \n",
    "#     # Validation phase\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         val_loss = 0.0\n",
    "#         val_samples = 0\n",
    "#         for inputs, labels in val_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             labels = labels.unsqueeze(1)\n",
    "#             loss = criterion(outputs, labels.float())\n",
    "#             val_loss += loss.item() * inputs.size(0)\n",
    "#             val_samples += inputs.size(0)\n",
    "        \n",
    "#         average_val_loss = val_loss / val_samples\n",
    "#         print('Epoch %d - Validation Loss: %.6f' % (epoch + 1, average_val_loss))\n",
    "        \n",
    "#         # Check if validation loss improved\n",
    "#         if average_val_loss < best_val_loss:\n",
    "#             best_val_loss = average_val_loss\n",
    "#             counter = 0\n",
    "#             torch.save(model, 'trained_model')  # Save the best model\n",
    "#         else:\n",
    "#             counter += 1\n",
    "#             if counter >= patience:\n",
    "#                 print('No improvement in validation loss. Early stopping.')\n",
    "#                 break\n",
    "        \n",
    "#     print('Epoch %d completed.' % (epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 190.603422 - Validation Loss: 3.509931\n",
      "Epoch 1 completed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-4d99e7cefbb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "best_val_loss = float('inf')\n",
    "patience = 5  # Number of epochs to wait for improvement\n",
    "counter = 0  # Counter to track the number of epochs without improvement\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        # L1 regularization\n",
    "        l1_lambda = 0.01  # Adjust the L1 regularization strength\n",
    "        l1_regularization = torch.tensor(0.)\n",
    "        for param in model.parameters():\n",
    "            l1_regularization += torch.norm(param, 1)\n",
    "        loss += l1_lambda * l1_regularization\n",
    "\n",
    "        # L2 regularization\n",
    "        l2_lambda = 0.01  # Adjust the L2 regularization strength\n",
    "        l2_regularization = torch.tensor(0.)\n",
    "        for param in model.parameters():\n",
    "            l2_regularization += torch.norm(param, 2)\n",
    "        loss += l2_lambda * l2_regularization\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_samples = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_samples += inputs.size(0)\n",
    "        \n",
    "        average_val_loss = val_loss / val_samples\n",
    "        # print('Epoch %d - Validation Loss: %.6f' % (epoch + 1, average_val_loss))\n",
    "        # Print the running loss and validation loss at the end of the epoch\n",
    "        print('Epoch %d - Training Loss: %.6f - Validation Loss: %.6f' % (epoch + 1, running_loss / len(train_loader), average_val_loss))\n",
    "\n",
    "        \n",
    "        # Check if validation loss improved\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            counter = 0\n",
    "            torch.save(model, 'trained_model')  # Save the best model\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print('No improvement in validation loss. Early stopping.')\n",
    "                break\n",
    "        \n",
    "    print('Epoch %d completed.' % (epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('trained_model')  # Replace 'trained_model.pth' with the path to your trained model file\n",
    "\n",
    "# Load and preprocess the input image\n",
    "input_image = Image.open('Test_Images\\Train\\drop_s41_v5_r0.5_str6_pos0_cam150.png')  # Replace 'input_image.jpg' with the path to your input image file\n",
    "input_image = input_image.convert('RGB')\n",
    "input_tensor = transform(input_image)\n",
    "\n",
    "# input_tensor = torchvision.transforms.ToTensor()(input_image).unsqueeze(0)  # Preprocess the image and add a batch dimension\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 42.47267532348633\n"
     ]
    }
   ],
   "source": [
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Convert the output to a readable format\n",
    "predicted_value = output.item()\n",
    "\n",
    "# Print the predicted value\n",
    "print('Predicted value:', predicted_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
