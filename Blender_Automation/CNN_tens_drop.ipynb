{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the CNN model\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.fc1 = nn.Linear(32 * 16 * 16, 256)\n",
    "#         self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))\n",
    "#         x = x.view(-1, 32 * 16 * 16)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "#         self.fc2 = nn.Linear(512, 256)\n",
    "#         self.fc3 = nn.Linear(256, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(torch.relu(self.conv1(x)))\n",
    "#         x = self.pool(torch.relu(self.conv2(x)))\n",
    "#         x = self.pool(torch.relu(self.conv3(x)))\n",
    "#         x = x.view(-1, 64 * 8 * 8)\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = self.pool(torch.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training dataset\n",
    "# Set up the data directories\n",
    "data_dir = 'Test_Images'\n",
    "train_dir = os.path.join(data_dir, 'Train')\n",
    "\n",
    "# Define a function to get the labels from the image filenames\n",
    "def get_label(filename):\n",
    "    match = re.search(r'\\d+\\.?\\d*', filename)\n",
    "    if match:\n",
    "        return float(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Define a list to store the image filenames and labels\n",
    "train_data = []\n",
    "\n",
    "# Iterate over the training images and add them to the list\n",
    "for filename in os.listdir(train_dir):\n",
    "    label = get_label(filename)\n",
    "    if label is not None:\n",
    "        train_data.append([os.path.join(train_dir, filename), label])\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "train_df = pd.DataFrame(train_data, columns=['filename', 'label'])\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "train_df.to_csv(os.path.join(data_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = self._load_data(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_data(self, csv_file):\n",
    "    # Load and preprocess data from the CSV file\n",
    "    # Example: Assuming the CSV file has two columns representing image paths and labels\n",
    "        data = []\n",
    "        with open(csv_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines[1:]:  # Skip the header row\n",
    "                # Split the line by comma or any other appropriate delimiter\n",
    "                image_path, label = line.strip().split(',')\n",
    "                data.append((image_path, float(label)))  # Parse the label as float\n",
    "        return data\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "csv_file = 'Test_Images/train.csv'  # Replace with the path to your CSV file\n",
    "image_folder = 'Test_Images/train'  # Replace with the path to your image folder\n",
    "dataset = CustomImageDataset(csv_file, image_folder, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "# # Access individual samples\n",
    "# image, label = dataset[0]\n",
    "# print(image.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])             # Need to be adjusted, acording to dataset\n",
    "])\n",
    "\n",
    "csv_file = 'Test_Images/train.csv'  # Replace with the path to your CSV file\n",
    "image_folder = 'Test_Images/train'  # Replace with the path to your image folder\n",
    "\n",
    "dataset = CustomImageDataset(csv_file, image_folder, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "model = CNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Validation Loss: 244.328896\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Validation Loss: 14.610093\n",
      "Epoch 2 completed.\n",
      "Epoch 3 - Validation Loss: 16.362730\n",
      "Epoch 3 completed.\n",
      "Epoch 4 - Validation Loss: 8.026246\n",
      "Epoch 4 completed.\n",
      "Epoch 5 - Validation Loss: 4.634348\n",
      "Epoch 5 completed.\n",
      "Epoch 6 - Validation Loss: 3.142521\n",
      "Epoch 6 completed.\n",
      "Epoch 7 - Validation Loss: 2.993510\n",
      "Epoch 7 completed.\n",
      "Epoch 8 - Validation Loss: 2.937714\n",
      "Epoch 8 completed.\n",
      "Epoch 9 - Validation Loss: 2.911790\n",
      "Epoch 9 completed.\n",
      "Epoch 10 - Validation Loss: 3.356578\n",
      "Epoch 10 completed.\n",
      "Epoch 11 - Validation Loss: 2.965926\n",
      "Epoch 11 completed.\n",
      "Epoch 12 - Validation Loss: 2.879856\n",
      "Epoch 12 completed.\n",
      "Epoch 13 - Validation Loss: 2.891520\n",
      "Epoch 13 completed.\n",
      "Epoch 14 - Validation Loss: 2.906295\n",
      "Epoch 14 completed.\n",
      "Epoch 15 - Validation Loss: 3.850196\n",
      "Epoch 15 completed.\n",
      "Epoch 16 - Validation Loss: 3.768750\n",
      "Epoch 16 completed.\n",
      "Epoch 17 - Validation Loss: 2.928847\n",
      "Epoch 17 completed.\n",
      "Epoch 18 - Validation Loss: 3.086167\n",
      "Epoch 18 completed.\n",
      "Epoch 19 - Validation Loss: 2.841243\n",
      "Epoch 19 completed.\n",
      "Epoch 20 - Validation Loss: 4.078133\n",
      "Epoch 20 completed.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()  # Set the model to training mode\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_samples = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_samples += inputs.size(0)\n",
    "        \n",
    "        average_val_loss = val_loss / val_samples\n",
    "        print('Epoch %d - Validation Loss: %.6f' % (epoch + 1, average_val_loss))\n",
    "        \n",
    "    print('Epoch %d completed.' % (epoch + 1))\n",
    "\n",
    "torch.save(model, 'trained_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 64])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('trained_model')  # Replace 'trained_model.pth' with the path to your trained model file\n",
    "\n",
    "# Load and preprocess the input image\n",
    "input_image = Image.open('Test_Images\\Train\\drop_s41_v5_r0.5_str6_pos0_cam3.png')  # Replace 'input_image.jpg' with the path to your input image file\n",
    "input_image = input_image.convert('RGB')\n",
    "input_tensor = transform(input_image)\n",
    "\n",
    "# input_tensor = torchvision.transforms.ToTensor()(input_image).unsqueeze(0)  # Preprocess the image and add a batch dimension\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: 43.54480743408203\n"
     ]
    }
   ],
   "source": [
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make a prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Convert the output to a readable format\n",
    "predicted_value = output.item()\n",
    "\n",
    "# Print the predicted value\n",
    "print('Predicted value:', predicted_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
