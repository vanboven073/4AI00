{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device for computation (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): # results in accuracy of 73.22%\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        x = self.leaky_relu(self.fc3(x))\n",
    "        x = self.leaky_relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module): # OVERFITS\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.conv6 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "#         self.conv7 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)  # Additional layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(1024 * 2 * 2, 1024)  # Updated input size\n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, 256)\n",
    "#         self.fc4 = nn.Linear(256, 128)\n",
    "#         self.fc5 = nn.Linear(128, 64)  # New layer with 64 output neurons\n",
    "#         self.fc6 = nn.Linear(64, 1)  # Additional layer with 1 output neuron\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv6(x)))\n",
    "#         x = self.leaky_relu(self.conv7(x))  # Additional layer\n",
    "#         x = x.view(-1, 1024 * 2 * 2)  # Reshape the tensor\n",
    "#         x = self.leaky_relu(self.fc1(x))\n",
    "#         x = self.leaky_relu(self.fc2(x))\n",
    "#         x = self.leaky_relu(self.fc3(x))\n",
    "#         x = self.leaky_relu(self.fc4(x))\n",
    "#         x = self.leaky_relu(self.fc5(x))  # Apply activation to new layer\n",
    "#         x = self.fc6(x)  # Pass through additional layer\n",
    "#         return x.squeeze(1)  # Squeeze the output tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(512 * 2 * 2, 2048)\n",
    "#         self.fc2 = nn.Linear(2048, 1024)\n",
    "#         self.fc3 = nn.Linear(1024, 512)\n",
    "#         self.fc4 = nn.Linear(512, 256)\n",
    "#         self.fc5 = nn.Linear(256, 1)\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "#         x = x.view(-1, 512 * 2 * 2)\n",
    "#         x = self.leaky_relu(self.fc1(x))\n",
    "#         x = self.leaky_relu(self.fc2(x))\n",
    "#         x = self.leaky_relu(self.fc3(x))\n",
    "#         x = self.leaky_relu(self.fc4(x))\n",
    "#         x = self.fc5(x)\n",
    "#         return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 3092.083582 - Validation Loss: 1247.871568 - Learning Rate: 0.001\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Training Loss: 836.791840 - Validation Loss: 245.936725 - Learning Rate: 0.001\n",
      "Epoch 2 completed.\n",
      "Epoch 3 - Training Loss: 548.975305 - Validation Loss: 336.333165 - Learning Rate: 0.001\n",
      "Epoch 3 completed.\n",
      "Epoch 4 - Training Loss: 498.934332 - Validation Loss: 355.005814 - Learning Rate: 0.001\n",
      "Epoch 4 completed.\n",
      "Epoch 5 - Training Loss: 495.527747 - Validation Loss: 242.853288 - Learning Rate: 0.001\n",
      "Epoch 5 completed.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4zUlEQVR4nO3deXxV5bXw8d/KDEmYEhBIgCQEQeYhIIJDQGutsyiKxQG1DqjY6m217Wsrrdert9ervTi1zooo4oBSB7QyiAKKgIggogECBBBImAIhCUnW+8feCYdwkpwMJ/skWd/P53D2efa0skn2Os/z7P1sUVWMMcaY6oR5HYAxxpjQZ8nCGGNMjSxZGGOMqZElC2OMMTWyZGGMMaZGliyMMcbUyJKFaVQi8qGIXNvQy3pJRLJF5KwgbHehiPzKnZ4oIh8Hsmwd9tNdRA6KSHhdYzXNnyULUyP3RFL+KhORwz6fJ9ZmW6r6C1V9qaGXDUUi8gcRWeSnPFFEikWkf6DbUtUZqnp2A8V1THJT1S2qGqeqpQ2x/Ur7UhFJb+jtmsZnycLUyD2RxKlqHLAFuMCnbEb5ciIS4V2UIWk6MEpEUiuVTwC+VdU1HsRkTJ1YsjB1JiKZIpIjIveIyE/ACyLSXkTeE5HdIrLXnU72Wce3aWWSiHwuIg+7y24SkV/UcdlUEVkkIvki8omIPCEir1QRdyAx3i8ii93tfSwiiT7zrxaRzSKSJyL/r6rjo6o5wHzg6kqzrgFeqimOSjFPEpHPfT7/TES+F5H9IvI4ID7zeorIfDe+XBGZISLt3HnTge7Av9ya4d0ikuLWACLcZbqKyBwR2SMiWSJyo8+2p4rILBF52T02a0Uko6pjUBURaetuY7d7LO8VkTB3XrqIfOr+bLki8rpbLiLyqIjscuetrk3tzNSPJQtTX52BDkAP4Cac36kX3M/dgcPA49WsfzKwHkgE/gY8JyJSh2VfBZYBCcBUjj9B+wokxl8C1wGdgCjgtwAi0hd4yt1+V3d/fk/wrpd8YxGR3sBg4LUA4ziOm7jeAu7FORYbgNG+iwAPuvGdBHTDOSao6tUcWzv8m59dvAbkuOtfBvyXiJzpM/9CYCbQDpgTSMx+PAa0BdKAM3AS6HXuvPuBj4H2OMf2Mbf8bOB04ER331cAeXXYt6kLVbWXvQJ+AdnAWe50JlAMxFSz/GBgr8/nhcCv3OlJQJbPvNaAAp1rsyzOibYEaO0z/xXglQB/Jn8x3uvz+VZgrjv9Z2Cmz7xY9xicVcW2WwMHgFHu5weAd+t4rD53p68BvvBZTnBO7r+qYrsXA1/7+z90P6e4xzICJ7GUAvE+8x8EXnSnpwKf+MzrCxyu5tgqkF6pLBwoAvr6lN0MLHSnXwaeBpIrrTcW+AEYCYR5/bfQ0l5WszD1tVtVC8s/iEhrEfmn27RwAFgEtJOqr7T5qXxCVQvcybhaLtsV2ONTBrC1qoADjPEnn+kCn5i6+m5bVQ9RzbdbN6Y3gGvcWtBEnNpGXY5VucoxqO9nEekkIjNFZJu73VdwaiCBKD+W+T5lm4Ekn8+Vj02M1K6/KhGntra5in3cjZMAl7nNXNcDqOp8nFrME8BOEXlaRNrUYr+mHixZmPqqPGzxfwC9gZNVtQ1OswH4tKkHwQ6gg4i09inrVs3y9Ylxh++23X0m1LDOS8DlwM+AeOC9esZROQbh2J/3QZz/l4Hudq+qtM3qhprejnMs433KugPbaoipNnKBIzjNb8ftQ1V/UtUbVbUrTo3jSXGvqFLVaao6DOiH0xz1uwaMy1TDkoVpaPE4be/7RKQDcF+wd6iqm4HlwFQRiRKRU4ALghTjm8D5InKqiEQBf6Xmv6PPgH04TSszVbW4nnG8D/QTkXHuN/o7cJrjysUDB93tJnH8CXUnTl/BcVR1K7AEeFBEYkRkIHADMMPf8gGKcrcVIyIxbtks4AERiReRHsBdODUgRGS8T0f/XpzkVioiw0XkZBGJBA4BhThNZqYRWLIwDe3vQCucb49fAHMbab8TgVNwmoT+E3gdp13cn79TxxhVdS1wG06H+g6ck1lODesoTjt8D/e9XnGoai4wHngI5+ftBSz2WeQvwFBgP05iebvSJh4E7hWRfSLyWz+7uBKnH2M7MBu4T1X/HUhsVViLkxTLX9cBU3BO+BuBz3GO5/Pu8sOBL0XkIE4H+q9VdRPQBngG55hvxvnZH65HXKYWxO04MqZZcS+3/F5Vg16zMaYlsJqFaRbcJoqeIhImIucAFwHveByWMc2G3XFrmovOOM0tCTjNQpNV9WtvQzKm+bBmKGOMMTWyZihjjDE1arbNUImJiZqSkuJ1GMYY06SsWLEiV1U7Vi5vtskiJSWF5cuXex2GMcY0KSKy2V+5NUMZY4ypkSULY4wxNbJkYYwxpkbNts/CGNM4jhw5Qk5ODoWFhTUvbEJGTEwMycnJREZGBrS8JQtjTL3k5OQQHx9PSkoKVT+3yoQSVSUvL4+cnBxSUys/9dc/a4YyxtRLYWEhCQkJliiaEBEhISGhVrVBSxbGmHqzRNH01Pb/zJKFj9Iy5fWvtvDhtzu8DsUYY0KKJQsfYQIzvtzCgx9+T0lpmdfhGGMCkJeXx+DBgxk8eDCdO3cmKSmp4nNxcXG16y5fvpw77rijxn2MGjWqQWJduHAh559/foNsq7FZB7cPEeH2MencNH0Fc77ZzrihyTWvZIzxVEJCAqtWrQJg6tSpxMXF8dvfHn2mU0lJCRER/k91GRkZZGRk1LiPJUuWNEisTZnVLCo566QT6NM5nicWZFFaZiPyGtMUTZo0ibvuuosxY8Zwzz33sGzZMkaNGsWQIUMYNWoU69evB479pj916lSuv/56MjMzSUtLY9q0aRXbi4uLq1g+MzOTyy67jD59+jBx4kTKR+7+4IMP6NOnD6eeeip33HFHrWoQr732GgMGDKB///7cc889AJSWljJp0iT69+/PgAEDePTRRwGYNm0affv2ZeDAgUyYMKH+BytAQatZuM/aXQREu/t5U1Xvc581/DrOYxuzgctVda+7zh9wnvdbCtyhqh+55cOAF3EeQfkBzmMWg3ImDwsTbh+bzu2vfs2Ha3Zw/sCuwdiNMc3SX/61lu+2H2jQbfbt2ob7LuhX6/V++OEHPvnkE8LDwzlw4ACLFi0iIiKCTz75hD/+8Y+89dZbx63z/fffs2DBAvLz8+nduzeTJ08+7j6Er7/+mrVr19K1a1dGjx7N4sWLycjI4Oabb2bRokWkpqZy5ZVXBhzn9u3bueeee1ixYgXt27fn7LPP5p133qFbt25s27aNNWvWALBv3z4AHnroITZt2kR0dHRFWWMIZs2iCBirqoOAwcA5IjIS+D0wT1V7AfPcz4hIX2AC0A84B3hSRMLdbT0F3ITzrOFe7vyg+UX/LqR1jOXx+VmUWe3CmCZp/PjxhIc7p5D9+/czfvx4+vfvz5133snatWv9rnPeeecRHR1NYmIinTp1YufOncctM2LECJKTkwkLC2Pw4MFkZ2fz/fffk5aWVnHPQm2SxVdffUVmZiYdO3YkIiKCiRMnsmjRItLS0ti4cSNTpkxh7ty5tGnTBoCBAwcyceJEXnnllSqb14IhaHtyv/kfdD9Gui/Fedxlplv+ErAQuMctn6mqRcAmEckCRohINtBGVZcCiMjLwMXAh8GKPTzM6bu4a9Y3fLJuJ2f36xysXRnTrNSlBhAssbGxFdN/+tOfGDNmDLNnzyY7O5vMzEy/60RHR1dMh4eHU1JSEtAy9WnoqGrd9u3b88033/DRRx/xxBNPMGvWLJ5//nnef/99Fi1axJw5c7j//vtZu3ZtoySNoPZZiEi4iKwCdgH/VtUvgRNUdQeA+97JXTwJ2Oqzeo5bluROVy4PqgsHdaV7h9Y8viCrXr8Ixhjv7d+/n6Qk57Tx4osvNvj2+/Tpw8aNG8nOzgbg9ddfD3jdk08+mU8//ZTc3FxKS0t57bXXOOOMM8jNzaWsrIxLL72U+++/n5UrV1JWVsbWrVsZM2YMf/vb39i3bx8HDx6seScNIKjpSFVLgcEi0g6YLSL9q1nc3x0iWk358RsQuQmnuYru3bvXLthKIsLDuDWzJ79/+1s+/WE3mb071bySMSYk3X333Vx77bU88sgjjB07tsG336pVK5588knOOeccEhMTGTFiRJXLzps3j+Tko1davvHGGzz44IOMGTMGVeXcc8/loosu4ptvvuG6666jrMy5jP/BBx+ktLSUq666iv3796Oq3HnnnbRr167Bfx5/Gu0Z3CJyH3AIuBHIVNUdItIFWKiqvd3ObVT1QXf5j4CpOJ3gC1S1j1t+pbv+zdXtLyMjQ+v78KPikjIy/2cBXdq14s1bTrG7VI3xY926dZx00kleh+G5gwcPEhcXh6py22230atXL+68806vw6qWv/87EVmhqsddTxy0ZigR6ejWKBCRVsBZwPfAHOBad7FrgXfd6TnABBGJFpFUnI7sZW5TVb6IjBTnbH2NzzpBFRURxi2ZPVmxeS9LN+Y1xi6NMU3UM888w+DBg+nXrx/79+/n5pur/T7b5ASzGaoL8JJ7RVMYMEtV3xORpcAsEbkB2AKMB1DVtSIyC/gOKAFuc5uxACZz9NLZDwli53Zll2d047H5WTw+P4tRPRMba7fGmCbmzjvvDPmaRH0E82qo1cAQP+V5wJlVrPMA8ICf8uVAdf0dQRMTGc7Np6fxn++vY8XmPQzr0cGLMIwxxlN2B3cAfnlydzrERvHY/CyvQzHGGE9YsghA66gIbjg1lYXrd7M6Z5/X4RhjTKOzZBGga07pQZuYCB632oUxpgWyZBGg+JhIrhudysff7WTdjoYd+8YYU3eZmZl89NFHx5T9/e9/59Zbb612nfJL688991y/YyxNnTqVhx9+uNp9v/POO3z33XcVn//85z/zySef1CJ6/0JxKHNLFrVw3egUYqPCeWKB1S6MCRVXXnklM2fOPKZs5syZAY/P9MEHH9T5xrbKyeKvf/0rZ511Vp22FeosWdRCu9ZRXDMqhfe/3UHWrsa5xd4YU73LLruM9957j6KiIgCys7PZvn07p556KpMnTyYjI4N+/fpx3333+V0/JSWF3NxcAB544AF69+7NWWedVTGMOTj3UAwfPpxBgwZx6aWXUlBQwJIlS5gzZw6/+93vGDx4MBs2bGDSpEm8+eabgHOn9pAhQxgwYADXX399RXwpKSncd999DB06lAEDBvD9998H/LN6OZS5Pfyolm44NZUXFm/iyYVZPHL5YK/DMSa0fPh7+Onbht1m5wHwi4eqnJ2QkMCIESOYO3cuF110ETNnzuSKK65ARHjggQfo0KEDpaWlnHnmmaxevZqBAwf63c6KFSuYOXMmX3/9NSUlJQwdOpRhw4YBMG7cOG688UYA7r33Xp577jmmTJnChRdeyPnnn89ll112zLYKCwuZNGkS8+bN48QTT+Saa67hqaee4je/+Q0AiYmJrFy5kieffJKHH36YZ599tsbD4PVQ5lazqKXEuGgmntyDd1dtZ0tegdfhGGM4tinKtwlq1qxZDB06lCFDhrB27dpjmowq++yzz7jkkkto3bo1bdq04cILL6yYt2bNGk477TQGDBjAjBkzqhzivNz69etJTU3lxBNPBODaa69l0aJFFfPHjRsHwLBhwyoGH6yJ10OZW82iDm46PY3pX2zmqU+zeHCc/28pxrRI1dQAguniiy/mrrvuYuXKlRw+fJihQ4eyadMmHn74Yb766ivat2/PpEmTKCwsrHY7VY3/NmnSJN555x0GDRrEiy++yMKFC6vdTk1j7pUPc17VMOi12WZjDWVuNYs6OKFNDFdkdOPNFTls23fY63CMafHi4uLIzMzk+uuvr6hVHDhwgNjYWNq2bcvOnTv58MPqRwk6/fTTmT17NocPHyY/P59//etfFfPy8/Pp0qULR44cYcaMGRXl8fHx5OfnH7etPn36kJ2dTVaWczHM9OnTOeOMM+r1M3o9lLnVLOro5jPSeG3ZFp7+dAN/uciTkUiMMT6uvPJKxo0bV9EcNWjQIIYMGUK/fv1IS0tj9OjR1a4/dOhQrrjiCgYPHkyPHj047bTTKubdf//9nHzyyfTo0YMBAwZUJIgJEyZw4403Mm3atIqObYCYmBheeOEFxo8fT0lJCcOHD+eWW26p1c8TakOZN9oQ5Y2tIYYor8k9b65m9qptfH73GDq1iQnqvowJVTZEedMVEkOUtwSTM3tSUlrGM59t9DoUY4wJKksW9ZCSGMtFg5N45Yst5B0s8jocY4wJGksW9XTbmJ4UlpTy/OJNXodijGeaa3N2c1bb/zNLFvWU3imec/t34aUlm9lfcMTrcIxpdDExMeTl5VnCaEJUlby8PGJiAu9rtauhGsBtY9J5/9sdvLgkm1+f1cvrcIxpVMnJyeTk5LB7926vQzG1EBMTc8zVVjWxZNEA+nZtw1knncDzizdx/akpxMdEeh2SMY0mMjKS1NRUr8MwQWbNUA1kyth09h8+witfbPE6FGOMaXCWLBrIoG7tOP3Ejjz72UYKigO7fd8YY5oKSxYNaMrYdPIOFfPasq1eh2KMMQ3KkkUDGp7SgZFpHXh60QYKj5R6HY4xxjQYSxYNbMrYXuw8UMQbK3K8DsUYYxqMJYsGNqpnAkO7t+MfCzdwpLTM63CMMaZBWLJoYCLClLG92LbvMLNXbvM6HGOMaRCWLIIgs3dH+ie14cmFWZRY7cIY0wwELVmISDcRWSAi60RkrYj82i2fKiLbRGSV+zrXZ50/iEiWiKwXkZ/7lA8TkW/dedOkqsdZhQgR4fYxvcjOK+C91Tu8DscYY+otmDWLEuA/VPUkYCRwm4j0dec9qqqD3dcHAO68CUA/4BzgSREJd5d/CrgJ6OW+zgli3A3i7L4n0PuEeB5fkEVZmY2ZY4xp2oKWLFR1h6qudKfzgXVAUjWrXATMVNUiVd0EZAEjRKQL0EZVl6ozUtnLwMXBiruhhIUJt41NJ2vXQeau/cnrcIwxpl4apc9CRFKAIcCXbtHtIrJaRJ4XkfZuWRLgezdbjluW5E5XLve3n5tEZLmILA+FQc3OG9CFtMRYHpufZSNyGmOatKAnCxGJA94CfqOqB3CalHoCg4EdwP+WL+pnda2m/PhC1adVNUNVMzp27Fjf0OstPEy4dUw663YcYN66XV6HY4wxdRbUZCEikTiJYoaqvg2gqjtVtVRVy4BngBHu4jlAN5/Vk4Htbnmyn/Im4aLBXenWoRWPLbDahTGm6Qrm1VACPAesU9VHfMq7+Cx2CbDGnZ4DTBCRaBFJxenIXqaqO4B8ERnpbvMa4N1gxd3QIsPDmHxGOt9s3cdnP+Z6HY4xxtRJMGsWo4GrgbGVLpP9m3sZ7GpgDHAngKquBWYB3wFzgdtUtXyApcnAszid3huAD4MYd4O7dFgSXdrG8Pj8LK9DMcaYOgnaw49U9XP89zd8UM06DwAP+ClfDvRvuOgaV3REODefnsbUf33HFxvzGJmW4HVIxhhTK3YHdyOZMKI7iXHRVrswxjRJliwaSUxkODednsrnWbms3LLX63CMMaZWLFk0ookn96B960irXRhjmhxLFo0oNjqCG05NZf73u1izbb/X4RhjTMAsWTSya0alEB8TYbULY0yTYsmikbWJieS6USnMXfsT63/K9zocY4wJiCULD1w3OpXYqHCeWGC1C2NM02DJwgPtY6O46pQevLd6Oxt3H/Q6HGOMqZElC4/ceFoaURFhPLlwg9ehGGNMjSxZeCQxLporR3Rn9tfb2LqnwOtwjDGmWpYsPHTz6T0JF+GpT612YYwJbZYsPNS5bQzjM5J5c3kOO/Yf9jocY4ypkiULj91yRk/KVPnnpxu9DsUYY6pkycJj3Tq05pIhSby2bAu78gu9DscYY/yyZBECbh2TzpHSMp77bJPXoRhjjF+WLEJAamIsFwzqyvQvNrPnULHX4RhjzHEsWYSI28ekU1BcyguLrXZhjAk9lixCRK8T4vlF/868uDib/YePeB2OMcYcw5JFCLl9bDr5RSW8vCTb61CMMeYYlixCSL+ubTmzTyeeW7yJg0UlXodjjDEVLFmEmNvHprOv4AgzvtjsdSjGGFPBkkWIGdK9Paf1SuSZzzZyuLjU63CMMQawZBGSpoztRe7BYmZ+tcXrUIwxBrBkEZJGpHZgRGoH/vnpRopKrHZhjPGeJYsQdcfYXvx0oJA3V+R4HYoxxliyCFWj0xMY3K0dTy3cwJHSMq/DMca0cEFLFiLSTUQWiMg6EVkrIr92yzuIyL9F5Ef3vb3POn8QkSwRWS8iP/cpHyYi37rzpomIBCvuUCEi3HFmOjl7D/PO19u8DscY08IFs2ZRAvyHqp4EjARuE5G+wO+BearaC5jnfsadNwHoB5wDPCki4e62ngJuAnq5r3OCGHfIGNO7E/26tuHJhRsoLVOvwzHGtGBBSxaqukNVV7rT+cA6IAm4CHjJXewl4GJ3+iJgpqoWqeomIAsYISJdgDaqulRVFXjZZ51mTUSYMjadTbmHeG/1dq/DMca0YI3SZyEiKcAQ4EvgBFXdAU5CATq5iyUBW31Wy3HLktzpyuX+9nOTiCwXkeW7d+9u0J/BK2f37cyJJ8TxxIIsyqx2YYzxSNCThYjEAW8Bv1HVA9Ut6qdMqyk/vlD1aVXNUNWMjh071j7YEBQWJtw2Jp0fdh7k4+9+8jocY0wLFdRkISKROIlihqq+7RbvdJuWcN93ueU5QDef1ZOB7W55sp/yFuP8gV1JTYzlsflZOC1xxhjTuIJ5NZQAzwHrVPURn1lzgGvd6WuBd33KJ4hItIik4nRkL3ObqvJFZKS7zWt81mkRwsOEWzN7snb7ARas31XzCsYY08CCWbMYDVwNjBWRVe7rXOAh4Gci8iPwM/czqroWmAV8B8wFblPV8tuXJwPP4nR6bwA+DGLcIeniIUkkt2/FtHlWuzDGNL6IYG1YVT/Hf38DwJlVrPMA8ICf8uVA/4aLrumJDA9jcmZP/t/sNSzOyuPUXoleh2SMaUHsDu4m5LJhyXRuE8Nj83/0OhRjTAtjyaIJiY4I5+Yz0vhy0x6WbdrjdTjGmBbEkkUTM2F4dxLjoqx2YYxpVJYsmphWUeHceFoan/2Yy6qt+7wOxxjTQliyaIImjuxBu9aRPG61C2NMI7Fk0QTFRUdww+hUPlm3i7Xb93sdjjGmBbBk0URdMyqF+OgInliQ5XUoxpgWwJJFE9W2VSSTRqfw4Zqf+HFnvtfhGGOaOUsWTdh1o1NpFRlutQtjTNAFlCxEJFZEwtzpE0XkQneQQOOhDrFRXD2yB3O+2c6m3ENeh2OMacYCrVksAmJEJAnn6XbXAS8GKygTuBtOSyUyPIynFlrtwhgTPIEmC1HVAmAc8JiqXgL0DV5YJlCd4mO4ckR33l65ja17CrwOxxjTTAWcLETkFGAi8L5bFrRBCE3t3HxGGmEi/HPRBq9DMcY0U4Emi98AfwBmq+paEUkDFgQtKlMrXdq24rKMZGZ9lcNP+wu9DscY0wwFlCxU9VNVvVBV/9vt6M5V1TuCHJuphcln9KRUlacXbfQ6FGNMMxTo1VCvikgbEYnFeTjRehH5XXBDM7XRrUNrLhmSxKvLNpN7sMjrcIwxzUygzVB9VfUAcDHwAdAd5yl4JoTcmtmT4pIynv1sk9ehGGOamUCTRaR7X8XFwLuqegSwZ3uGmLSOcZw/sCvTl2az91Cx1+EYY5qRQJPFP4FsIBZYJCI9gAPBCsrU3W1j0jlUXMoLS7K9DsUY04wE2sE9TVWTVPVcdWwGxgQ5NlMHvTvHc06/zryweBMHCo94HY4xppkItIO7rYg8IiLL3df/4tQyTAi6fWw6+YUlTF+62etQjDHNRKDNUM8D+cDl7usA8EKwgjL10z+pLWP7dOLZzzZyqKjE63CMMc1AoMmip6rep6ob3ddfgLRgBmbq5/ax6ewtOMKrX27xOhRjTDMQaLI4LCKnln8QkdHA4eCEZBrC0O7tOTU9kX8u2kjhkVKvwzHGNHGBJotbgCdEJFtEsoHHgZuDFpVpELePTSf3YBGvf7XV61CMMU1coFdDfaOqg4CBwEBVHQKMDWpkpt5GpiUwIqUD//h0A0UlVrswxtRdrZ6Up6oH3Du5Ae6qblkReV5EdonIGp+yqSKyTURWua9zfeb9QUSyRGS9iPzcp3yYiHzrzpsmIlKbmFu628ems2N/IW+v3OZ1KMaYJqw+j1Wt6aT9InCOn/JHVXWw+/oAQET6AhOAfu46T4pIuLv8U8BNQC/35W+bpgqn9UpkULd2PLkwiyOlZV6HY4xpouqTLKod7kNVFwF7AtzWRcBMVS1S1U1AFjBCRLoAbVR1qaoq8DLOkCMmQCLClDHpbN1zmDmrtnsdjjGmiao2WYhIvogc8PPKB7rWcZ+3i8hqt5mqvVuWBPj2wua4ZUnudOXyquK9qfzGwd27d9cxvObnzJM6cVKXNjyxIIvSMhvSyxhTe9UmC1WNV9U2fl7xqlqXJ+U9BfQEBgM7gP91y/01aWk15VXF+7SqZqhqRseOHesQXvMkIkwZm87G3EN88O0Or8MxxjRB9WmGqjVV3amqpapaBjwDjHBn5QDdfBZNBra75cl+yk0tndOvM+md4nh8fhZlVrswxtRSoyYLtw+i3CVA+ZVSc4AJIhItIqk4HdnLVHUHkC8iI92roK4B3m3MmJuLsDDh9jHprN+Zz7/X7fQ6HGNMExO0ZCEirwFLgd4ikiMiNwB/cy+DXY0zau2dAKq6FpiF8xS+ucBtqlp+Y8Bk4FmcTu8NwIfBirm5O39gF1ISWvPY/B9xrhcwxpjASHM9aWRkZOjy5cu9DiPkzPpqK3e/tZoXrhvOmN6dvA7HGBNiRGSFqmZULm/UZijjvUuGJpHUrhWPzbPahTEmcJYsWpjI8DBuyezJyi37WLohz+twjDFNhCWLFmj8sGROaBPNtPk/eh2KMaaJsGTRAsVEhnPT6T35YuMevsoO9CZ7Y0xLZsmihfrliO4kxEbx2Pwsr0MxxjQBlixaqFZR4fzqtDQW/bCbb7bu8zocY0yIs2TRgl19Sg/atoq02oUxpkaWLFqwuOgIrh+dyifrdvLd9gM1r2CMabEsWbRwk0anEB8dwRMLrHZhjKmaJYsWrm2rSK4Z1YMP1uwga1e+1+EYY0KUJYvKFk+D79/3OopGdcOpacREhPPEgg1eh2KMCVGWLHyVFMO6OfD6VbByutfRNJoOsVFcNbI7767axua8Q16HY4wJQZYsfEVEwdXvQNoYmHM7fP4otJDxk248PY2I8DCetNqFMcYPSxaVRcfBlTOh/2XwyVT4+F4oK/M6qqDrFB/DlcO78dbKHLbtO+x1OMaYEGPJwp+IKBj3DJx8Cyx9HN6ZDKVHvI4q6G4+oyci8I+FVrswxhzLkkVVwsLgnIdg7J9g9UyY+Usobt7t+V3bteKyYcm8vnwrOw8Ueh2OMSaEWLKojgic/lu44P8g6xN4+WIoaN4D700+I53SMuWZRRu9DsUYE0IsWQRi2CQY/xLsWAUv/AL2b/M6oqDpntCaiwZ3ZcaXW8g7WOR1OMaYEGHJIlB9L4Sr3nISxfM/h9zm+yyI28akU1hSynOfb/I6FGNMiLBkURupp8N170NJoZMwtq3wOqKg6NkxjvMGdOHlpZvZV1DsdTjGmBBgyaK2ugyC6z+CqDh48QLYMN/riILi9rHpHCwq4cUl2V6HYowJAZYs6iKhJ9zwMXRIhRmXw5q3vI6owfXp3Iaz+57A859vIr+w+V82bIypniWLuorvDJPeh+Th8OYNsOwZryNqcFPG9uJAYQnTv9jsdSjGGI9ZsqiPVu3g6reh97nwwW9hwX81q+FBBiS3JbN3R579bBMFxSVeh2OM8ZAli/qKbAWXvwxDroJP/xvevwvKSr2OqsFMGduLPYeKefXLLV6HYozxUNCShYg8LyK7RGSNT1kHEfm3iPzovrf3mfcHEckSkfUi8nOf8mEi8q07b5qISLBirrPwCLjwcTj1Tlj+PLx5HZQ0j3sUhvVoz6ieCTy9aCOFR5pPEjTG1E4waxYvAudUKvs9ME9VewHz3M+ISF9gAtDPXedJEQl313kKuAno5b4qbzM0iMBZU+HsB+C7d2HGZVDUPB4mNGVsL3blF/HG8q1eh2KM8UjQkoWqLgIqj41xEfCSO/0ScLFP+UxVLVLVTUAWMEJEugBtVHWpqirwss86oWnU7XDJPyF7Mbx4Phzc7XVE9TYyrQMZPdrz1MINFJc0/xF4jTHHa+w+ixNUdQeA+97JLU8CfL+25rhlSe505XK/ROQmEVkuIst37/bwJD1ogjPM+e71zs17e7O9i6UBiAhTzuzF9v2FzP46p+YVjDHNTqh0cPvrh9Bqyv1S1adVNUNVMzp27NhgwdXJiWfDtXOgIA+e+znsXOttPPV0eq9EBia35YkFGygptdqFMS1NYyeLnW7TEu77Lrc8B+jms1wysN0tT/ZT3jR0GwHXzwUJcwYg3LzU64jqTESYMrYXW/YU8K/VTee/wBjTMBo7WcwBrnWnrwXe9SmfICLRIpKK05G9zG2qyheRke5VUNf4rNM0dDoJbvgIYjvC9Ith/YdeR1RnZ53UiT6d43l8fhalZc3nfhJjTM2Ceensa8BSoLeI5IjIDcBDwM9E5EfgZ+5nVHUtMAv4DpgL3Kaq5ddpTgaexen03gA0vbNtu+7OeFKd+sLMifD1DK8jqpPy2sWG3YeYu+Ynr8MxxjQi0WZ0x7GvjIwMXb58uddhHKvoILx+FWxcAD/7K4z+tdcR1VppmXL2o58SGR7GB3ecRlhY6N32YoypOxFZoaoZlctDpYO7ZYiOg1++Dv3Gwb//DB/f2+SGBwkPE24fm873P+Uz7/tdNa9gjGkWLFk0tohouPRZGH4jLHkM3rkVSpvWuEsXDOxKj4TWPDb/R5przdQYcyxLFl4IC4dz/wcy/wjfvAqvT4TiAq+jClhEeBi3ZvZkdc5+Fv2Y63U4xphGYMnCKyKQeQ+c9wj88BFMvwQO7/U6qoBdMiSZpHateGye1S6MaQksWXht+A0w/kXYvhJeOBcO7PA6ooBERYRxyxlpLN+8ly82Vh7VxRjT3FiyCAX9LoaJb8C+LfDc2ZCb5XVEARmf0Y1O8dHcNH05t0xfwfSl2WzcfdBqGsY0Q3bpbCjZ/jW8cpkzfdWb0HWIt/EE4Nuc/by8NJslG/LYtu8wAF3axjCqZyKj0xMYnZ7ICW1iPI7SGBOoqi6dtWQRanKz3P6LPTBhBqRleh1RQFSVzXkFLN6Qy5KsPJZsyGVvgfPs7vROcYzumcCo9ERGpiXQtlWkx9EaY6piyaIpObADXhkHeVkw7mnod4nXEdVaWZny3Y4DLNmQy+KsPJZt2sPhI6WECQxIasuo9ERG90wkI6U9MZHhNW/QGNMoLFk0NYf3wqsTYOuXcN7DMPxXXkdUL8UlZazauo/Ps3JZkpXLqq37KClToiLCyOjRntHpiYzqmcCApLZEhFtXmjFesWTRFBUXOI9o/WGuc0/GGXc7l9w2AweLSvhq0x4WZ+WyeEMe63YcACA+JoKRaQmM7un0d6R3iiMUn6RrTHNlyaKpKj0Cc+5wbt4bfiP84m8Q1vy+eeceLGLphryKZqste5ybFDvFRzPKTRyj0xPp2q6Vx5Ea07xVlSwivAjG1EJ4JFz8JMQmwpJpzsOULvmHM2xIM5IYF80Fg7pywaCuAGzdU8CSDbl8npXH51m5vLPKeYZGamJsRfI4JS2B9rFRXoZtTIthNYumZPH/OQMQpmXCFa9AdLzXETUKVWX9znwWZ+WxJCuXLzft4WBRCSLQt0sbTk1PZFR6IsNT2tM6yr7/GFMf1gzVXHw9A+ZMgS6DnBv5YhO9jqjRHSktY3XOPhZn5bE4K5evt+yjuLSMyHBhSPf2jO6ZyKm9EhiY3I5I6yw3plYsWTQn6z+ENyZB225w9dvOw5VasMPFpXyVvYfFG3JZnJXL2u0HUIXYqHBOTkuoaLbqfUK8PX/DmBpYsmhuNi+F166AyFgnYXQ6yeuIQsbeQ8V8sTGv4gbBjbmHAEiIjXLv73CSR7cOrT2O1JjQY8miOdq5FqaPg5JC+OUs6H6y1xGFpO37DrM4K5clG5xmq135RQB069CK0T0TK+7xSIhrXhcNGFMXliyaq72bneFBDmyHy1+GE8/2OqKQpqps2H2Qxe5VVl9szCO/0Hn4VJ/O8e4lugmMSE0gLto6y03LY8miOTu4G2ZcCj+tcS6zHTTB64iajJLSMtZsP+DWPHL5KnsvxSVlRIQJg7q1c5JHzwSGdG9PVIR1lpvmz5JFc1d4wHni3qZFcPYDMOp2ryNqkgqPlLJi896KO8u/zdlHmUKryHCGp3ao6O/o26WNdZabZsmSRUtQUgRv3wjfvQujfwNnTW02w4N4Zf/hI3y5MY8lG5xmq6xdBwFo3zqSU3omuEOxJ5KS0NqGJTHNgiWLlqKsFD74LSx/HoZcBef/H4Rb23tD2XmgsGJIkiVZuWzfXwhAUrtWFZfojuqZQCd7hodpoixZtCSqsPAh+PQh6H0uXPY8RNqYSg1NVcnOK6gYSXfpxjz2uc/w6NUpriJxjOyZQJsYe4aHaRosWbREXz4NH94N3U+BK1+DVu28jqhZK3+GR3l/x7JNeRQeKSNMYGByO+fJgT0T6ZfUlrjoCMKtz8OEIEsWLdWat+Dtm6Fjb7jqLYjv7HVELUZRSSlfb9nHEjd5rNq6j9Kyo39v0RFhxEZH0CoynNjocFpHRdA6ynl3PrvTUeG0qigrXybcZ93yZZz5loRMfYRUshCRbCAfKAVKVDVDRDoArwMpQDZwuarudZf/A3CDu/wdqvpRTfuwZOFjw3yYeZUzjtTVsyGhp9cRtUgHi0pYtimPjbsPUVBcyqHiEgqKSikoLqWguIRDxaUUFJUc8/mwu1xt/kxjIsMqkkpsVASt/SWeqHBaR5cv45OEfBLP0XUjaB0Zbld/tRChmCwyVDXXp+xvwB5VfUhEfg+0V9V7RKQv8BowAugKfAKcqKql1e3DkkUl21bAK5dBWLhTw+gyyOuITIBUlcIjZRQUlxxNMsWlFBQ504f9Jh5/y7jziko57Caj2mgV6SadaCeRVCSUqPBKicYnGVVRaypft5UloZDTFJ5ncRGQ6U6/BCwE7nHLZ6pqEbBJRLJwEsdSD2JsupKGwfUfOc/2fuE8pw8j9TSvozIBEBFaud/2Expwu2VlSmFJ6TFJpcA3oRxx3gsqyks5VOSTnNyy3INFFeuVl9XG8c1wxzaxRUeEuVeACyJQnlqc6cplcsy8o9Pue/l895/j1z++DJGj61ezzcrrl++ncll5nOKznYqy8s8+cVa3TY4pO7rNCwd1bfDHE3uVLBT4WEQU+KeqPg2coKo7AFR1h4h0cpdNAr7wWTfHLTuOiNwE3ATQvXvLHonVr44nHk0Yr4yDS5+Dvhd6HZXxSFiYuCfoCIhruO2WlSmHj5RWm3iqbHJzyw4VlbA7v4hDxSUUHSlDwW2Kc1pCVHHLlPK2EVWfz26h7zJaUaYV66PO5+q22RSdO6ALEeENu02vksVoVd3uJoR/i8j31Szrr47q97/QTTpPg9MMVf8wm6G2SXDdh/DqFfDGtXDeI5BxnddRmWYkLEycTvfoCKB5DM6oqj7JpuoEhJ8yvwlIK61TxTapWN//No/Zn0/iiwrCc1w8SRaqut193yUis3GalXaKSBe3VtEF2OUungN081k9GdjeqAE3N607wDXvOsnivd9AQS6c9lu729uYKpQ3EfmUeBWKZxp9ZDQRiRWR+PJp4GxgDTAHuNZd7FrgXXd6DjBBRKJFJBXoBSxr3KiboajWMOFVGHgFzP9PmPt7KCvzOipjTIjyomZxAjDb7RSKAF5V1bki8hUwS0RuALYA4wFUda2IzAK+A0qA22q6EsoEKDwSLv4HtE6EL56AQ7lw8VMQEeV1ZMaYENPoyUJVNwLHXbepqnnAmVWs8wDwQJBDa5nCwuDnD0BcR/hkKhze6zwXI7oBezyNMU2eDdBvnL6KU++ECx+HjQvg5QvhUJ7XURljQoglC3PU0Kvhilechyi9cA7s2+p1RMaYEGHJwhyrz3nOkCD5P8HzP4fd672OyBgTAkLpDm4TKlJGw3UfwPRxTsL45RvQbbjXUZnGUlYKZSXOq/SIz+cj7nupW15y/KvG5X3ml/rML/PZXqnvNo9AWCTEd3EGwfR9b93BLvduRJYsjH+dB8ANH8P0S5w+jMunQ6+zvI6qaTpS6NzLcijXeS/K93PCrHzSrXTCrG75Wp/Qa9i2/3tegy8swv+rtMi58KKy8KjjE0h8Z4jveuzn6HhLKg3AkoWpWodUJ2G8Mg5eu8K5zHbgeK+j8l5xARza7SaAvGMTge/nQ7uhIA+KD9Z9XxLunDDDI51BIMMinG/aYRHO5/BI/yfY8EjnXpqK5WtYNtBth/vMD/OZH+67nM/2qtyGn/1Vd0IvKXKaRvN/gvwd7vv2o593rYMNC6DowPHrRsY6SaNNeRLxl1g62wPCamDJwlQvrhNMeh9mToS3f+Wc/Ebe4nVUDUfVOZkfynV+toqTfO6xZb6J4EiB/22FRzn3rMQmOO8dUo/9HNvRGSY+Ot45SdZ0gpVw59JmAxHR0L6H86pO0cFKCcX3fQfkfOV8Lik8ft2YdkeTSJuu/mstcSc4/z8tkCULU7OYtjDxTXjrBph7DxzaBWP/FJpVe1Uo3F/pJO9zsveXCEqL/G8rIsY5wbdOcE7yib2d9/LPrROd9/Jpa+7wXnQcRKdDYnrVy6hC4T4naRzY7j+5bFzovB93/684vxOVE0mbLpX6UxKbXaK3ZGECExnj3Kz33p3w2f86J93zHnW+HQdTWZnzh+3vxO83EeQ57fB+f4ZY51t+bEfnD7rzgONP/L41gahYO/k3RyLQqr3z6nRS1cuVlTm/W76J5MCOYz9v/9r5vavczxMW4dRC/HXM+yaWmHZN5nfMkoUJXFg4XPB/TtPUov+Bgj3OMOeRMYFvo6zU6az0PfmXn+SPSQh5R9+rGt0lus3Rk33bZOg6uOoTf2yitUmb2gkLc37X4zpV/7Cw0iNwcOfxNZTyxJK3AbI/d770VBYR45NMulSdXKJig/ZjBsqShakdERh7r3MCnnsPvHIpXPwEFB+qvpO3fN7hvaBVDFgY0+7oSb5DGiQPd5t5Oh5/4m+d4LRjG+O18Ejny0rb5OqXO3L42P6TY5LLT7DjG/hhrv8+seg21XTOdzk6L4h/E548VrUx2GNVG8HqN+CdW9zLLSsT5zp435P7Md/6E452+LZOdJZtoR2HxlRQdS6tPiap+Ous/wlKi49fv1UHp3P++rlOH1odNIXHqpqmZuB4SEiDbSsrdfh2dNqDwxr4UV3GNHciENPGeXU8serlVJ1m4OMSyXY4uAuiGn4gUEsWpn6ShjkvY0zjEXEv1kiAzv0bZZfN69ouY4wxQWHJwhhjTI0sWRhjjKmRJQtjjDE1smRhjDGmRpYsjDHG1MiShTHGmBpZsjDGGFOjZjvch4jsBjbXcfVEILcBw2koFlftWFy1Y3HVTnONq4eqdqxc2GyTRX2IyHJ/Y6N4zeKqHYurdiyu2mlpcVkzlDHGmBpZsjDGGFMjSxb+Pe11AFWwuGrH4qodi6t2WlRc1mdhjDGmRlazMMYYUyNLFsYYY2rUYpOFiDwvIrtEZE0V80VEpolIloisFpGhIRJXpojsF5FV7uvPjRRXNxFZICLrRGStiPzazzKNfswCjKvRj5mIxIjIMhH5xo3rL36W8eJ4BRKXJ79j7r7DReRrEXnPzzxP/iYDiMurv8lsEfnW3edxz5Bu8OOlqi3yBZwODAXWVDH/XOBDQICRwJchElcm8J4Hx6sLMNSdjgd+APp6fcwCjKvRj5l7DOLc6UjgS2BkCByvQOLy5HfM3fddwKv+9u/V32QAcXn1N5kNJFYzv0GPV4utWajqImBPNYtcBLysji+AdiLSJQTi8oSq7lDVle50PrAOSKq0WKMfswDjanTuMTjofox0X5WvJvHieAUSlydEJBk4D3i2ikU8+ZsMIK5Q1aDHq8UmiwAkAVt9PucQAich1yluM8KHItKvsXcuIinAEJxvpb48PWbVxAUeHDO36WIVsAv4t6qGxPEKIC7w5nfs78DdQFkV8736/fo71ccF3hwvBT4WkRUicpOf+Q16vCxZVE38lIXCN7CVOGO3DAIeA95pzJ2LSBzwFvAbVT1QebafVRrlmNUQlyfHTFVLVXUwkAyMEJH+lRbx5HgFEFejHy8ROR/YpaorqlvMT1lQj1eAcXn1NzlaVYcCvwBuE5HTK81v0ONlyaJqOUA3n8/JwHaPYqmgqgfKmxFU9QMgUkQSG2PfIhKJc0Keoapv+1nEk2NWU1xeHjN3n/uAhcA5lWZ5+jtWVVweHa/RwIUikg3MBMaKyCuVlvHieNUYl1e/X6q63X3fBcwGRlRapEGPlyWLqs0BrnGvKBgJ7FfVHV4HJSKdRUTc6RE4/4d5jbBfAZ4D1qnqI1Us1ujHLJC4vDhmItJRRNq5062As4DvKy3mxfGqMS4vjpeq/kFVk1U1BZgAzFfVqyot1ujHK5C4PPr9ihWR+PJp4Gyg8hWUDXq8IuocbRMnIq/hXMWQKCI5wH04nX2o6j+AD3CuJsgCCoDrQiSuy4DJIlICHAYmqHvpQ5CNBq4GvnXbuwH+CHT3ic2LYxZIXF4csy7ASyISjnPymKWq74nILT5xeXG8AonLq9+x44TA8QokLi+O1wnAbDdHRQCvqurcYB4vG+7DGGNMjawZyhhjTI0sWRhjjKmRJQtjjDE1smRhjDGmRpYsjDHG1MiShTG1ICKlcnR00VUi8vsG3HaKVDHasDFea7H3WRhTR4fdoTKMaVGsZmFMAxDn2QL/Lc6zIpaJSLpb3kNE5onzPIF5ItLdLT9BRGa7g899IyKj3E2Fi8gz4jxr4mP3LmtE5A4R+c7dzkyPfkzTglmyMKZ2WlVqhrrCZ94BVR0BPI4zUinu9MuqOhCYAUxzy6cBn7qDzw0F1rrlvYAnVLUfsA+41C3/PTDE3c4twfnRjKma3cFtTC2IyEFVjfNTng2MVdWN7sCGP6lqgojkAl1U9YhbvkNVE0VkN5CsqkU+20jBGTK8l/v5HiBSVf9TROYCB3FGNH3H55kUxjQKq1kY03C0iumqlvGnyGe6lKP9iucBTwDDgBUiYv2NplFZsjCm4Vzh877UnV6CM1opwETgc3d6HjAZKh5G1KaqjYpIGNBNVRfgPISnHXBc7caYYLJvJ8bUTiuf0W0B5qpq+eWz0SLyJc6XsCvdsjuA50Xkd8Bujo78+WvgaRG5AacGMRmoavjocOAVEWmL80CbR91nURjTaKzPwpgG4PZZZKhqrtexGBMM1gxljDGmRlazMMYYUyOrWRhjjKmRJQtjjDE1smRhjDGmRpYsjDHG1MiShTHGmBr9fypVOUAUub5SAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Train_510: 1.72%\n",
      "Epoch 1 - Training Loss: 1741.487198 - Validation Loss: 560.528879 - Learning Rate: 0.001\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Training Loss: 697.028828 - Validation Loss: 241.719791 - Learning Rate: 0.001\n",
      "Epoch 2 completed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-212-73b95132d340>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Move inputs to the device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Move labels to the device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-209-2921596abb8d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 459\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create training dataset\n",
    "# Set up the data directories\n",
    "sets = ['Train_510', 'Train_1020', 'Train_2040', 'Train_4080', 'Train_8160', 'Train_10200']\n",
    "best_train_losses = {}  # Dictionary to store the best training loss for each item\n",
    "best_val_losses = {}  # Dictionary to store the best validation loss for each item\n",
    "accuracy = []\n",
    "for item in sets:\n",
    "    data_dir = 'Test_Images'\n",
    "    train_dir = os.path.join(data_dir, item)\n",
    "\n",
    "    # Define a function to get the labels from the image filenames\n",
    "    def get_label(filename):\n",
    "        match = re.search(r'\\d+\\.?\\d*', filename)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Define a list to store the image filenames and labels\n",
    "    train_data = []\n",
    "\n",
    "    # Iterate over the training images and add them to the list\n",
    "    for filename in os.listdir(train_dir):\n",
    "        label = get_label(filename)\n",
    "        if label is not None:\n",
    "            train_data.append([os.path.join(train_dir, filename), label])\n",
    "\n",
    "    # Convert the list to a dataframe\n",
    "    train_df = pd.DataFrame(train_data, columns=['filename', 'label'])\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    train_df.to_csv(os.path.join(data_dir, item+'.csv'), index=False)\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = self._load_data(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_data(self, csv_file):\n",
    "        data = []\n",
    "        with open(csv_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines[1:]:\n",
    "                image_path, label = line.strip().split(',')\n",
    "                data.append((image_path, float(label)))\n",
    "        return data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.4753, 0.4753, 0.4753])\n",
    "])\n",
    "\n",
    "for item in sets:\n",
    "    csv_file = f'Test_Images/{item}.csv'\n",
    "    image_folder = f'Test_Images/{item}'\n",
    "\n",
    "    dataset = CustomImageDataset(csv_file, image_folder, transform=transform)\n",
    "\n",
    "    train_size = int(0.6 * len(dataset))\n",
    "    val_size = int(0.2 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    num_epochs = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_learning_rate = None\n",
    "    patience = 5\n",
    "    counter = 0\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_numbers = []\n",
    "    item_train_losses = []  # List to store training losses for the current item\n",
    "    item_val_losses = []  # List to store validation losses for the current item\n",
    "\n",
    "    model = CNN().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            inputs = inputs.to(device)  # Move inputs to the device\n",
    "            labels = labels.to(device)  # Move labels to the device\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "\n",
    "            l1_lambda = 0.01\n",
    "            l1_regularization = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l1_regularization += torch.norm(param, 1)\n",
    "            loss += l1_lambda * l1_regularization\n",
    "\n",
    "            l2_lambda = 0.01\n",
    "            l2_regularization = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l2_regularization += torch.norm(param, 2)\n",
    "            loss += l2_lambda * l2_regularization\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            val_samples = 0\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_samples += inputs.size(0)\n",
    "\n",
    "            average_val_loss = val_loss / val_samples\n",
    "\n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            val_losses.append(average_val_loss)\n",
    "            item_train_losses.append(running_loss / len(train_loader))\n",
    "            item_val_losses.append(average_val_loss)\n",
    "\n",
    "            epoch_numbers.append(epoch + 1)\n",
    "            print('Epoch %d - Training Loss: %.6f - Validation Loss: %.6f - Learning Rate: %.3f' % (epoch + 1, running_loss / len(train_loader), average_val_loss, learning_rate))\n",
    "\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f'trained_model_{item}.pt')\n",
    "\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print('No improvement in validation loss. Early stopping.')\n",
    "                break\n",
    "\n",
    "        print('Epoch %d completed.' % (epoch + 1))\n",
    "\n",
    "    best_train_loss = min(item_train_losses)\n",
    "    best_train_losses[item] = best_train_loss\n",
    "\n",
    "    best_val_loss = min(item_val_losses)\n",
    "    best_val_losses[item] = best_val_loss\n",
    "    # Plotting the losses\n",
    "    # epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epoch_numbers, train_losses, label='Training Loss')\n",
    "    plt.plot(epoch_numbers, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'loss_plot_{item}.jpeg', format='jpeg')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "   \n",
    "    # # Create a DataFrame to store the predictions\n",
    "    # predictions_df = pd.DataFrame(columns=['Image', 'Real Value', 'Predicted Value', 'Difference'])\n",
    "\n",
    "    # # Iterate over the figures in the folder\n",
    "    # for filename in os.listdir(image_folder):\n",
    "    #     if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust the file extensions as per your figures\n",
    "    #         image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "    #         # Load and preprocess the image\n",
    "    #         image = Image.open(image_path).convert('RGB')\n",
    "    #         input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "    #         # Extract the real value from the filename\n",
    "    #         real_value = int(filename.split('_')[1][1:])  # Adjust the splitting pattern to extract the desired value\n",
    "            \n",
    "    #         # Make the prediction\n",
    "    #         with torch.no_grad():\n",
    "    #             output = model(input_tensor)\n",
    "    #         predicted_value = output.item()\n",
    "            \n",
    "    #         # Calculate the difference between predicted and real value\n",
    "    #         difference = predicted_value - real_value\n",
    "\n",
    "    #         # Add the prediction, real value, and difference to the DataFrame\n",
    "    #         predictions_df = predictions_df.append({'Image': filename, 'Real Value': real_value, 'Predicted Value': predicted_value, 'Difference': difference}, ignore_index=True)\n",
    "\n",
    "    #     # # Print the predictions table\n",
    "    #     # print(predictions_df)\n",
    "\n",
    "    # Create a DataFrame to store the predictions\n",
    "    predictions_test_df = pd.DataFrame(columns=['Real Value', 'Predicted Value', 'Difference'])\n",
    "\n",
    "    model = CNN().to(device)  # Instantiate a new instance of the CNN class\n",
    "    model.load_state_dict(torch.load(f'trained_model_{item}.pt'))  # Load the state dictionary of the pre-trained model\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables for tracking correct predictions and total samples\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Define the range for considering a prediction as correct\n",
    "    max_range = 0.5\n",
    "\n",
    "    # Iterate over the test data\n",
    "    for sample in test_loader:\n",
    "\n",
    "        # Move the input data to the device\n",
    "        inputs = sample[0].to(device)  # Assuming the input images are the first element in each sample\n",
    "        labels = sample[1].to(device)  # Assuming the labels are the second element in each sample\n",
    "\n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            predicted_values = model(inputs).squeeze().tolist()\n",
    "\n",
    "        # Get the predicted labels\n",
    "        predicted_labels = outputs  # Assuming the model output is a single scalar value\n",
    "\n",
    "        # Calculate the number of correct predictions within the range\n",
    "        # correct_predictions += ((predicted_labels >= min_range) & (predicted_labels <= max_range) & (labels >= min_range) & (labels <= max_range)).sum().item()\n",
    "        \n",
    "    # Iterate over the predicted values and add them to the DataFrame\n",
    "        for i in range(len(predicted_values)):\n",
    "            real_value = labels[i].item()\n",
    "            predicted_value = predicted_values[i]\n",
    "\n",
    "            # Check if the predicted value is within the desired range (40-70)\n",
    "            if real_value >= 40 and real_value <= 70:\n",
    "                # Calculate the difference between predicted and real value\n",
    "                difference = predicted_value - real_value\n",
    "\n",
    "                # Add the prediction, real value, and difference to the DataFrame\n",
    "                predictions_test_df = predictions_test_df.append({'Real Value': real_value, 'Predicted Value': predicted_value, 'Difference': difference}, ignore_index=True)\n",
    "\n",
    "                # Check if the prediction is correct within the desired range\n",
    "                if abs(real_value - predicted_value) <= max_range:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy_value = correct_predictions / (len(predictions_test_df)-1)\n",
    "    accuracy.append(accuracy_value)\n",
    "\n",
    "    # # Print the predictions DataFrame\n",
    "    # print(predictions_test_df)\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f\"Accuracy for {item}: {accuracy_value * 100:.2f}%\")\n",
    "    \n",
    "for item in sets:\n",
    "    print(f\"Item: {item}\")\n",
    "    print(f\"Best Validation Loss: {best_val_losses[item]}\")\n",
    "    print(f\"Best Training Loss: {best_train_losses[item]}\")\n",
    "    print(f\"Accuracy for {item}: {accuracy_value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Train_510\n",
      "Best Validation Loss: 213.3171792123832\n",
      "Best Training Loss: 344.830419921875\n",
      "Accuracy for Train_510: 0.00%\n",
      "Item: Train_1020\n",
      "Best Validation Loss: 2.5618433928957174\n",
      "Best Training Loss: 65.54328365325928\n",
      "Accuracy for Train_1020: 3.15%\n",
      "Item: Train_2040\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Train_2040'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-9cca8083b397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Item: {item}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best Validation Loss: {best_val_losses[item]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best Training Loss: {best_train_losses[item]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy for {item}: {accuracy[i] * 100:.2f}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Train_2040'"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(sets):\n",
    "    print(f\"Item: {item}\")\n",
    "    print(f\"Best Validation Loss: {best_val_losses[item]}\")\n",
    "    print(f\"Best Training Loss: {best_train_losses[item]}\")\n",
    "    print(f\"Accuracy for {item}: {accuracy[i] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-2026af660b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# sets = ['Train_510', 'Train_1020', 'Train_2040', 'Train_4080', 'Train_8160', 'Train_10200']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data set size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2888\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m         edgecolors=None, *, plotnonfinite=False, data=None, **kwargs):\n\u001b[1;32m-> 2890\u001b[1;33m     __ret = gca().scatter(\n\u001b[0m\u001b[0;32m   2891\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2892\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                 **kwargs)\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4439\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4441\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD9CAYAAACsq4z3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMTUlEQVR4nO3df6jd913H8efLZFWsXSvtXdmSKPkjXRdkle2YTUTt2FyTioShQjqxrAih0Kr/CK1/qIOCMlGRsq5ZGKHunwXFqnGtjT/YLFqKucGubVozLulsblPp7SaDddCa9u0f91SOp+fec5Kem5D3ng+43PP9fj/nfN/558mX7z3nJFWFJOnS930XewBJ0nwYdElqwqBLUhMGXZKaMOiS1IRBl6QmpgY9yaEkLyV5eo3jSXJvkqUkTyb5wPzHlCRNM8sV+gPA7nWO7wF2DH/2A/e//bEkSedqatCr6lHgW+ss2Qt8sVY9DlyV5N3zGlCSNJvNc3iNLcDpke3l4b4Xxxcm2c/qVTyXX375B6+//vo5nF6SvnccP3785apamHRsHkHPhH0Tv0+gqg4CBwEGg0EtLi7O4fSS9L0jyX+udWwe73JZBraNbG8FzszhdSVJ52AeQT8C3Dp8t8uHgW9X1Vtut0iSNtbUWy5JvgTcCFyTZBn4PeAdAFV1AHgYuBlYAr4L3LZRw0qS1jY16FV1y5TjBdwxt4kkSefFT4pKUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxExBT7I7yckkS0nunnD8yiR/m+RrSU4kuW3+o0qS1jM16Ek2AfcBe4CdwC1Jdo4tuwN4pqpuAG4E/jjJZXOeVZK0jlmu0HcBS1V1qqpeAw4De8fWFHBFkgA/BHwLODvXSSVJ65ol6FuA0yPby8N9oz4LvA84AzwF/GZVvTH+Qkn2J1lMsriysnKeI0uSJpkl6Jmwr8a2bwKeAN4D/Djw2STvfMuTqg5W1aCqBgsLC+c4qiRpPbMEfRnYNrK9ldUr8VG3AQ/WqiXgOeD6+YwoSZrFLEE/BuxIsn34h859wJGxNc8DHwVIci3wXuDUPAeVJK1v87QFVXU2yZ3AUWATcKiqTiS5fXj8AHAP8ECSp1i9RXNXVb28gXNLksZMDTpAVT0MPDy278DI4zPAx+c7miTpXPhJUUlqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEzMFPcnuJCeTLCW5e401NyZ5IsmJJP883zElSdNsnrYgySbgPuDngGXgWJIjVfXMyJqrgM8Bu6vq+STv2qB5JUlrmOUKfRewVFWnquo14DCwd2zNJ4EHq+p5gKp6ab5jSpKmmSXoW4DTI9vLw32jrgN+OMlXkxxPcuukF0qyP8liksWVlZXzm1iSNNEsQc+EfTW2vRn4IPDzwE3A7yS57i1PqjpYVYOqGiwsLJzzsJKktU29h87qFfm2ke2twJkJa16uqleAV5I8CtwAfH0uU0qSpprlCv0YsCPJ9iSXAfuAI2Nr/gb46SSbk/wg8CHg2fmOKklaz9Qr9Ko6m+RO4CiwCThUVSeS3D48fqCqnk3yCPAk8Abwhap6eiMHlyT9f6kavx1+YQwGg1pcXLwo55akS1WS41U1mHTMT4pKUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxExBT7I7yckkS0nuXmfdTyR5PckvzW9ESdIspgY9ySbgPmAPsBO4JcnONdZ9Bjg67yElSdPNcoW+C1iqqlNV9RpwGNg7Yd2vA38JvDTH+SRJM5ol6FuA0yPby8N9/yfJFuATwIH1XijJ/iSLSRZXVlbOdVZJ0jpmCXom7Kux7T8F7qqq19d7oao6WFWDqhosLCzMOKIkaRabZ1izDGwb2d4KnBlbMwAOJwG4Brg5ydmq+ut5DClJmm6WoB8DdiTZDrwA7AM+Obqgqra/+TjJA8CXjbkkXVhTg15VZ5Pcyeq7VzYBh6rqRJLbh8fXvW8uSbowZrlCp6oeBh4e2zcx5FX1qbc/liTpXPlJUUlqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEzMFPcnuJCeTLCW5e8LxX0ny5PDnsSQ3zH9USdJ6pgY9ySbgPmAPsBO4JcnOsWXPAT9bVe8H7gEOzntQSdL6ZrlC3wUsVdWpqnoNOAzsHV1QVY9V1X8PNx8Hts53TEnSNLMEfQtwemR7ebhvLb8G/N2kA0n2J1lMsriysjL7lJKkqWYJeibsq4kLk4+wGvS7Jh2vqoNVNaiqwcLCwuxTSpKm2jzDmmVg28j2VuDM+KIk7we+AOypqm/OZzxJ0qxmuUI/BuxIsj3JZcA+4MjogiQ/AjwI/GpVfX3+Y0qSppl6hV5VZ5PcCRwFNgGHqupEktuHxw8AvwtcDXwuCcDZqhps3NiSpHGpmng7fMMNBoNaXFy8KOeWpEtVkuNrXTD7SVFJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKamCnoSXYnOZlkKcndE44nyb3D408m+cD8R5UkrWdq0JNsAu4D9gA7gVuS7BxbtgfYMfzZD9w/5zklSVPMcoW+C1iqqlNV9RpwGNg7tmYv8MVa9ThwVZJ3z3lWSdI6Ns+wZgtwemR7GfjQDGu2AC+OLkqyn9UreIDvJDl5TtNKF841wMsXewhpgh9d68AsQc+EfXUea6iqg8DBGc4pXVRJFqtqcLHnkM7FLLdcloFtI9tbgTPnsUaStIFmCfoxYEeS7UkuA/YBR8bWHAFuHb7b5cPAt6vqxfEXkiRtnKm3XKrqbJI7gaPAJuBQVZ1Icvvw+AHgYeBmYAn4LnDbxo0sXRDeGtQlJ1VvudUtSboE+UlRSWrCoEtSEwZdkpow6LrkJLk6yRPDn/9K8sLI9mVTnjtIcu95nvcbSZ4anmdxZP8vJzmR5I0kg7Hn/PbwO45OJrnpfM4rzco/iuqSluTTwHeq6o9G9m2uqrMbcK5vAIOqenls//uAN4DPA79VVYvD/TuBL7H69RnvAf4RuK6qXp/3bBJ4ha4mkjyQ5E+SfAX4TJJdSR5L8u/D3+8drrsxyZeHjz+d5FCSryY5leQ3zufcVfVsVU36Gou9wOGqerWqnmP1bb27zvOfKE01y0f/pUvFdcDHqur1JO8Efmb4OYqPAb8P/OKE51wPfAS4AjiZ5P6q+p81Xr+Av09SwOeHX2Wxni3A4yPbb37HkbQhDLo6+YuR2xlXAn+WZAerIX7HGs95qKpeBV5N8hJwLavhneSnqupMkncB/5DkP6rq0XXmmek7jqR58ZaLOnll5PE9wFeq6seAXwB+YI3nvDry+HXWucipqjPD3y8Bf8X02yd+x5EuKIOurq4EXhg+/tTbfbEklye54s3HwMeBp6c87QiwL8n3J9nO6n8A829vdxZpLQZdXf0h8AdJ/pXV7yB6u64F/iXJ11iN8kNV9QhAkk8kWQZ+EngoyVGAqjoB/DnwDPAIcIfvcNFG8m2LktSEV+iS1ITvcpFGJLka+KcJhz5aVd+80PNI58JbLpLUhLdcJKkJgy5JTRh0SWrCoEtSE/8LYBzL1c+TWkgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(sets, accuracy)\n",
    "plt.xlabel('Data set size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Different Sets')\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels if needed\n",
    "plt.savefig('Accuracy per data set.jpeg', format='jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Train_2040'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-3d025d43b9f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare data for scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_val_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_val_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_train_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-176-3d025d43b9f1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare data for scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_val_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_val_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_train_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Train_2040'"
     ]
    }
   ],
   "source": [
    "# Prepare data for scatter plot\n",
    "x_values = sets\n",
    "y_val_losses = [best_val_losses[item] for item in sets]\n",
    "y_train_losses = [best_train_losses[item] for item in sets]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(x_values, y_val_losses, label='Best Validation Loss')\n",
    "plt.scatter(x_values, y_train_losses, label='Best Training Loss')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Sets')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Best Validation and Training Loss per set')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('Best_losses_per_set.jpeg', format='jpeg')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
