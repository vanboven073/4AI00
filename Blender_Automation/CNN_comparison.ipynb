{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device for computation (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): # results in accuracy of 73.22%\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        x = self.leaky_relu(self.fc3(x))\n",
    "        x = self.leaky_relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module): # OVERFITS\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.conv6 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "#         self.conv7 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)  # Additional layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(1024 * 2 * 2, 1024)  # Updated input size\n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, 256)\n",
    "#         self.fc4 = nn.Linear(256, 128)\n",
    "#         self.fc5 = nn.Linear(128, 64)  # New layer with 64 output neurons\n",
    "#         self.fc6 = nn.Linear(64, 1)  # Additional layer with 1 output neuron\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv6(x)))\n",
    "#         x = self.leaky_relu(self.conv7(x))  # Additional layer\n",
    "#         x = x.view(-1, 1024 * 2 * 2)  # Reshape the tensor\n",
    "#         x = self.leaky_relu(self.fc1(x))\n",
    "#         x = self.leaky_relu(self.fc2(x))\n",
    "#         x = self.leaky_relu(self.fc3(x))\n",
    "#         x = self.leaky_relu(self.fc4(x))\n",
    "#         x = self.leaky_relu(self.fc5(x))  # Apply activation to new layer\n",
    "#         x = self.fc6(x)  # Pass through additional layer\n",
    "#         return x.squeeze(1)  # Squeeze the output tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(512 * 2 * 2, 2048)\n",
    "#         self.fc2 = nn.Linear(2048, 1024)\n",
    "#         self.fc3 = nn.Linear(1024, 512)\n",
    "#         self.fc4 = nn.Linear(512, 256)\n",
    "#         self.fc5 = nn.Linear(256, 1)\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "#         x = x.view(-1, 512 * 2 * 2)\n",
    "#         x = self.leaky_relu(self.fc1(x))\n",
    "#         x = self.leaky_relu(self.fc2(x))\n",
    "#         x = self.leaky_relu(self.fc3(x))\n",
    "#         x = self.leaky_relu(self.fc4(x))\n",
    "#         x = self.fc5(x)\n",
    "#         return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 3379.062720 - Validation Loss: 410.269249 - Learning Rate: 0.001\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Training Loss: 2241.410620 - Validation Loss: 2047.496338 - Learning Rate: 0.001\n",
      "Epoch 2 completed.\n",
      "Epoch 3 - Training Loss: 1071.052859 - Validation Loss: 612.289337 - Learning Rate: 0.001\n",
      "Epoch 3 completed.\n",
      "Epoch 4 - Training Loss: 623.198019 - Validation Loss: 236.923051 - Learning Rate: 0.001\n",
      "Epoch 4 completed.\n",
      "Epoch 5 - Training Loss: 504.651608 - Validation Loss: 217.809458 - Learning Rate: 0.001\n",
      "Epoch 5 completed.\n",
      "Epoch 6 - Training Loss: 451.240970 - Validation Loss: 216.996097 - Learning Rate: 0.001\n",
      "Epoch 6 completed.\n",
      "Epoch 7 - Training Loss: 460.527063 - Validation Loss: 236.779404 - Learning Rate: 0.001\n",
      "Epoch 7 completed.\n",
      "Epoch 8 - Training Loss: 425.311450 - Validation Loss: 263.644596 - Learning Rate: 0.001\n",
      "Epoch 8 completed.\n",
      "Epoch 9 - Training Loss: 435.163913 - Validation Loss: 226.345298 - Learning Rate: 0.001\n",
      "Epoch 9 completed.\n",
      "Epoch 10 - Training Loss: 418.564041 - Validation Loss: 234.583239 - Learning Rate: 0.001\n",
      "Epoch 10 completed.\n",
      "Epoch 11 - Training Loss: 429.169513 - Validation Loss: 210.109764 - Learning Rate: 0.001\n",
      "Epoch 11 completed.\n",
      "Epoch 12 - Training Loss: 410.140201 - Validation Loss: 211.055557 - Learning Rate: 0.001\n",
      "Epoch 12 completed.\n",
      "Epoch 13 - Training Loss: 397.279333 - Validation Loss: 229.379581 - Learning Rate: 0.001\n",
      "Epoch 13 completed.\n",
      "Epoch 14 - Training Loss: 390.910791 - Validation Loss: 232.156236 - Learning Rate: 0.001\n",
      "Epoch 14 completed.\n",
      "Epoch 15 - Training Loss: 405.416370 - Validation Loss: 214.782346 - Learning Rate: 0.001\n",
      "Epoch 15 completed.\n",
      "Epoch 16 - Training Loss: 380.299106 - Validation Loss: 193.422492 - Learning Rate: 0.001\n",
      "Epoch 16 completed.\n",
      "Epoch 17 - Training Loss: 360.870984 - Validation Loss: 205.283446 - Learning Rate: 0.001\n",
      "Epoch 17 completed.\n",
      "Epoch 18 - Training Loss: 385.053305 - Validation Loss: 174.606009 - Learning Rate: 0.001\n",
      "Epoch 18 completed.\n",
      "Epoch 19 - Training Loss: 348.086331 - Validation Loss: 174.765883 - Learning Rate: 0.001\n",
      "Epoch 19 completed.\n",
      "Epoch 20 - Training Loss: 328.848676 - Validation Loss: 155.147756 - Learning Rate: 0.001\n",
      "Epoch 20 completed.\n",
      "Epoch 21 - Training Loss: 296.898714 - Validation Loss: 195.958110 - Learning Rate: 0.001\n",
      "Epoch 21 completed.\n",
      "Epoch 22 - Training Loss: 327.905161 - Validation Loss: 184.406901 - Learning Rate: 0.001\n",
      "Epoch 22 completed.\n",
      "Epoch 23 - Training Loss: 304.775278 - Validation Loss: 178.138380 - Learning Rate: 0.001\n",
      "Epoch 23 completed.\n",
      "Epoch 24 - Training Loss: 286.349623 - Validation Loss: 124.579837 - Learning Rate: 0.001\n",
      "Epoch 24 completed.\n",
      "Epoch 25 - Training Loss: 249.712201 - Validation Loss: 93.899097 - Learning Rate: 0.001\n",
      "Epoch 25 completed.\n",
      "Epoch 26 - Training Loss: 228.170456 - Validation Loss: 87.312522 - Learning Rate: 0.001\n",
      "Epoch 26 completed.\n",
      "Epoch 27 - Training Loss: 212.069020 - Validation Loss: 113.499264 - Learning Rate: 0.001\n",
      "Epoch 27 completed.\n",
      "Epoch 28 - Training Loss: 216.436717 - Validation Loss: 58.072986 - Learning Rate: 0.001\n",
      "Epoch 28 completed.\n",
      "Epoch 29 - Training Loss: 209.035732 - Validation Loss: 51.791998 - Learning Rate: 0.001\n",
      "Epoch 29 completed.\n",
      "Epoch 30 - Training Loss: 191.358931 - Validation Loss: 43.778025 - Learning Rate: 0.001\n",
      "Epoch 30 completed.\n",
      "Epoch 31 - Training Loss: 174.808122 - Validation Loss: 58.986343 - Learning Rate: 0.001\n",
      "Epoch 31 completed.\n",
      "Epoch 32 - Training Loss: 195.576105 - Validation Loss: 27.420652 - Learning Rate: 0.001\n",
      "Epoch 32 completed.\n",
      "Epoch 33 - Training Loss: 180.567886 - Validation Loss: 33.812648 - Learning Rate: 0.001\n",
      "Epoch 33 completed.\n",
      "Epoch 34 - Training Loss: 164.870361 - Validation Loss: 39.505798 - Learning Rate: 0.001\n",
      "Epoch 34 completed.\n",
      "Epoch 35 - Training Loss: 157.247522 - Validation Loss: 16.896414 - Learning Rate: 0.001\n",
      "Epoch 35 completed.\n",
      "Epoch 36 - Training Loss: 148.092856 - Validation Loss: 30.276372 - Learning Rate: 0.001\n",
      "Epoch 36 completed.\n",
      "Epoch 37 - Training Loss: 147.281424 - Validation Loss: 14.261510 - Learning Rate: 0.001\n",
      "Epoch 37 completed.\n",
      "Epoch 38 - Training Loss: 140.210989 - Validation Loss: 13.636781 - Learning Rate: 0.001\n",
      "Epoch 38 completed.\n",
      "Epoch 39 - Training Loss: 133.820746 - Validation Loss: 7.900181 - Learning Rate: 0.001\n",
      "Epoch 39 completed.\n",
      "Epoch 40 - Training Loss: 129.894968 - Validation Loss: 10.435569 - Learning Rate: 0.001\n",
      "Epoch 40 completed.\n",
      "Epoch 41 - Training Loss: 131.487701 - Validation Loss: 6.736885 - Learning Rate: 0.001\n",
      "Epoch 41 completed.\n",
      "Epoch 42 - Training Loss: 127.397595 - Validation Loss: 5.547348 - Learning Rate: 0.001\n",
      "Epoch 42 completed.\n",
      "Epoch 43 - Training Loss: 123.994959 - Validation Loss: 10.609416 - Learning Rate: 0.001\n",
      "Epoch 43 completed.\n",
      "Epoch 44 - Training Loss: 123.377891 - Validation Loss: 4.337273 - Learning Rate: 0.001\n",
      "Epoch 44 completed.\n",
      "Epoch 45 - Training Loss: 117.787344 - Validation Loss: 3.884530 - Learning Rate: 0.001\n",
      "Epoch 45 completed.\n",
      "Epoch 46 - Training Loss: 117.087074 - Validation Loss: 4.071825 - Learning Rate: 0.001\n",
      "Epoch 46 completed.\n",
      "Epoch 47 - Training Loss: 119.742089 - Validation Loss: 3.652140 - Learning Rate: 0.001\n",
      "Epoch 47 completed.\n",
      "Epoch 48 - Training Loss: 115.910458 - Validation Loss: 8.743469 - Learning Rate: 0.001\n",
      "Epoch 48 completed.\n",
      "Epoch 49 - Training Loss: 114.722703 - Validation Loss: 3.266591 - Learning Rate: 0.001\n",
      "Epoch 49 completed.\n",
      "Epoch 50 - Training Loss: 109.754585 - Validation Loss: 3.758473 - Learning Rate: 0.001\n",
      "Epoch 50 completed.\n",
      "Epoch 51 - Training Loss: 108.284624 - Validation Loss: 3.144500 - Learning Rate: 0.001\n",
      "Epoch 51 completed.\n",
      "Epoch 52 - Training Loss: 106.862123 - Validation Loss: 2.343589 - Learning Rate: 0.001\n",
      "Epoch 52 completed.\n",
      "Epoch 53 - Training Loss: 106.809346 - Validation Loss: 2.246247 - Learning Rate: 0.001\n",
      "Epoch 53 completed.\n",
      "Epoch 54 - Training Loss: 104.975066 - Validation Loss: 3.094831 - Learning Rate: 0.001\n",
      "Epoch 54 completed.\n",
      "Epoch 55 - Training Loss: 106.705890 - Validation Loss: 2.205904 - Learning Rate: 0.001\n",
      "Epoch 55 completed.\n",
      "Epoch 56 - Training Loss: 102.488824 - Validation Loss: 2.139874 - Learning Rate: 0.001\n",
      "Epoch 56 completed.\n",
      "Epoch 57 - Training Loss: 100.933009 - Validation Loss: 6.611548 - Learning Rate: 0.001\n",
      "Epoch 57 completed.\n",
      "Epoch 58 - Training Loss: 101.666637 - Validation Loss: 1.822946 - Learning Rate: 0.001\n",
      "Epoch 58 completed.\n",
      "Epoch 59 - Training Loss: 99.952415 - Validation Loss: 9.753038 - Learning Rate: 0.001\n",
      "Epoch 59 completed.\n",
      "Epoch 60 - Training Loss: 98.822097 - Validation Loss: 5.176879 - Learning Rate: 0.001\n",
      "Epoch 60 completed.\n",
      "Epoch 61 - Training Loss: 96.097095 - Validation Loss: 1.914588 - Learning Rate: 0.001\n",
      "Epoch 61 completed.\n",
      "Epoch 62 - Training Loss: 94.586265 - Validation Loss: 1.683766 - Learning Rate: 0.001\n",
      "Epoch 62 completed.\n",
      "Epoch 63 - Training Loss: 93.587423 - Validation Loss: 1.852318 - Learning Rate: 0.001\n",
      "Epoch 63 completed.\n",
      "Epoch 64 - Training Loss: 92.934504 - Validation Loss: 4.464416 - Learning Rate: 0.001\n",
      "Epoch 64 completed.\n",
      "Epoch 65 - Training Loss: 92.894894 - Validation Loss: 2.926044 - Learning Rate: 0.001\n",
      "Epoch 65 completed.\n",
      "Epoch 66 - Training Loss: 93.061050 - Validation Loss: 1.915853 - Learning Rate: 0.001\n",
      "Epoch 66 completed.\n",
      "Epoch 67 - Training Loss: 91.337450 - Validation Loss: 1.942725 - Learning Rate: 0.001\n",
      "Epoch 67 completed.\n",
      "Epoch 68 - Training Loss: 89.065777 - Validation Loss: 1.608856 - Learning Rate: 0.001\n",
      "Epoch 68 completed.\n",
      "Epoch 69 - Training Loss: 88.243449 - Validation Loss: 1.869640 - Learning Rate: 0.001\n",
      "Epoch 69 completed.\n",
      "Epoch 70 - Training Loss: 86.206148 - Validation Loss: 2.583518 - Learning Rate: 0.001\n",
      "Epoch 70 completed.\n",
      "Epoch 71 - Training Loss: 88.386015 - Validation Loss: 8.037485 - Learning Rate: 0.001\n",
      "Epoch 71 completed.\n",
      "Epoch 72 - Training Loss: 93.394824 - Validation Loss: 2.966139 - Learning Rate: 0.001\n",
      "Epoch 72 completed.\n",
      "Epoch 73 - Training Loss: 91.249765 - Validation Loss: 8.873893 - Learning Rate: 0.001\n",
      "Epoch 73 completed.\n",
      "Epoch 74 - Training Loss: 88.645473 - Validation Loss: 13.517881 - Learning Rate: 0.001\n",
      "Epoch 74 completed.\n",
      "Epoch 75 - Training Loss: 85.398486 - Validation Loss: 1.722165 - Learning Rate: 0.001\n",
      "Epoch 75 completed.\n",
      "Epoch 76 - Training Loss: 81.035985 - Validation Loss: 2.124432 - Learning Rate: 0.001\n",
      "Epoch 76 completed.\n",
      "Epoch 77 - Training Loss: 81.252998 - Validation Loss: 9.036479 - Learning Rate: 0.001\n",
      "Epoch 77 completed.\n",
      "Epoch 78 - Training Loss: 82.145089 - Validation Loss: 1.580549 - Learning Rate: 0.001\n",
      "Epoch 78 completed.\n",
      "Epoch 79 - Training Loss: 78.753156 - Validation Loss: 1.479565 - Learning Rate: 0.001\n",
      "Epoch 79 completed.\n",
      "Epoch 80 - Training Loss: 78.088876 - Validation Loss: 4.784442 - Learning Rate: 0.001\n",
      "Epoch 80 completed.\n",
      "Epoch 81 - Training Loss: 78.181487 - Validation Loss: 1.322904 - Learning Rate: 0.001\n",
      "Epoch 81 completed.\n",
      "Epoch 82 - Training Loss: 77.971832 - Validation Loss: 8.225239 - Learning Rate: 0.001\n",
      "Epoch 82 completed.\n",
      "Epoch 83 - Training Loss: 78.678387 - Validation Loss: 1.207569 - Learning Rate: 0.001\n",
      "Epoch 83 completed.\n",
      "Epoch 84 - Training Loss: 75.441088 - Validation Loss: 1.791697 - Learning Rate: 0.001\n",
      "Epoch 84 completed.\n",
      "Epoch 85 - Training Loss: 74.800917 - Validation Loss: 4.514988 - Learning Rate: 0.001\n",
      "Epoch 85 completed.\n",
      "Epoch 86 - Training Loss: 75.257220 - Validation Loss: 1.080048 - Learning Rate: 0.001\n",
      "Epoch 86 completed.\n",
      "Epoch 87 - Training Loss: 74.952680 - Validation Loss: 4.651025 - Learning Rate: 0.001\n",
      "Epoch 87 completed.\n",
      "Epoch 88 - Training Loss: 74.046775 - Validation Loss: 1.731476 - Learning Rate: 0.001\n",
      "Epoch 88 completed.\n",
      "Epoch 89 - Training Loss: 71.136018 - Validation Loss: 0.996652 - Learning Rate: 0.001\n",
      "Epoch 89 completed.\n",
      "Epoch 90 - Training Loss: 72.413159 - Validation Loss: 1.193061 - Learning Rate: 0.001\n",
      "Epoch 90 completed.\n",
      "Epoch 91 - Training Loss: 69.377181 - Validation Loss: 1.364204 - Learning Rate: 0.001\n",
      "Epoch 91 completed.\n",
      "Epoch 92 - Training Loss: 70.939011 - Validation Loss: 1.190536 - Learning Rate: 0.001\n",
      "Epoch 92 completed.\n",
      "Epoch 93 - Training Loss: 67.985448 - Validation Loss: 1.767545 - Learning Rate: 0.001\n",
      "Epoch 93 completed.\n",
      "Epoch 94 - Training Loss: 69.888675 - Validation Loss: 3.793955 - Learning Rate: 0.001\n",
      "Epoch 94 completed.\n",
      "Epoch 95 - Training Loss: 69.971196 - Validation Loss: 7.633128 - Learning Rate: 0.001\n",
      "Epoch 95 completed.\n",
      "Epoch 96 - Training Loss: 72.569312 - Validation Loss: 1.666909 - Learning Rate: 0.001\n",
      "Epoch 96 completed.\n",
      "Epoch 97 - Training Loss: 66.112495 - Validation Loss: 1.400765 - Learning Rate: 0.001\n",
      "Epoch 97 completed.\n",
      "Epoch 98 - Training Loss: 64.711844 - Validation Loss: 0.947543 - Learning Rate: 0.001\n",
      "Epoch 98 completed.\n",
      "Epoch 99 - Training Loss: 64.119763 - Validation Loss: 0.899763 - Learning Rate: 0.001\n",
      "Epoch 99 completed.\n",
      "Epoch 100 - Training Loss: 64.340817 - Validation Loss: 2.001965 - Learning Rate: 0.001\n",
      "Epoch 100 completed.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Train_510: 6.67%\n",
      "Epoch 1 - Training Loss: 2701.188101 - Validation Loss: 1917.528682 - Learning Rate: 0.001\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Training Loss: 858.650496 - Validation Loss: 197.862016 - Learning Rate: 0.001\n",
      "Epoch 2 completed.\n",
      "Epoch 3 - Training Loss: 508.211218 - Validation Loss: 197.198435 - Learning Rate: 0.001\n",
      "Epoch 3 completed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-ae35f29639e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create training dataset\n",
    "# Set up the data directories\n",
    "sets = ['Train_510', 'Train_1020', 'Train_2040', 'Train_4080', 'Train_8160', 'Train_10200']\n",
    "best_train_losses = {}  # Dictionary to store the best training loss for each item\n",
    "best_val_losses = {}  # Dictionary to store the best validation loss for each item\n",
    "accuracy = []\n",
    "for item in sets:\n",
    "    data_dir = 'Test_Images'\n",
    "    train_dir = os.path.join(data_dir, item)\n",
    "\n",
    "    # Define a function to get the labels from the image filenames\n",
    "    def get_label(filename):\n",
    "        match = re.search(r'\\d+\\.?\\d*', filename)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Define a list to store the image filenames and labels\n",
    "    train_data = []\n",
    "\n",
    "    # Iterate over the training images and add them to the list\n",
    "    for filename in os.listdir(train_dir):\n",
    "        label = get_label(filename)\n",
    "        if label is not None:\n",
    "            train_data.append([os.path.join(train_dir, filename), label])\n",
    "\n",
    "    # Convert the list to a dataframe\n",
    "    train_df = pd.DataFrame(train_data, columns=['filename', 'label'])\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    train_df.to_csv(os.path.join(data_dir, item+'.csv'), index=False)\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = self._load_data(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_data(self, csv_file):\n",
    "        data = []\n",
    "        with open(csv_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines[1:]:\n",
    "                image_path, label = line.strip().split(',')\n",
    "                data.append((image_path, float(label)))\n",
    "        return data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.4753, 0.4753, 0.4753])\n",
    "])\n",
    "\n",
    "for item in sets:\n",
    "    csv_file = f'Test_Images/{item}.csv'\n",
    "    image_folder = f'Test_Images/{item}'\n",
    "\n",
    "    dataset = CustomImageDataset(csv_file, image_folder, transform=transform)\n",
    "\n",
    "    train_size = int(0.6 * len(dataset))\n",
    "    val_size = int(0.2 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    num_epochs = 100\n",
    "    best_val_loss = float('inf')\n",
    "    best_learning_rate = None\n",
    "    patience = 100\n",
    "    counter = 0\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_numbers = []\n",
    "    item_train_losses = []  # List to store training losses for the current item\n",
    "    item_val_losses = []  # List to store validation losses for the current item\n",
    "\n",
    "    model = CNN()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "\n",
    "            l1_lambda = 0.01\n",
    "            l1_regularization = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l1_regularization += torch.norm(param, 1)\n",
    "            loss += l1_lambda * l1_regularization\n",
    "\n",
    "            l2_lambda = 0.01\n",
    "            l2_regularization = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l2_regularization += torch.norm(param, 2)\n",
    "            loss += l2_lambda * l2_regularization\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            val_samples = 0\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_samples += inputs.size(0)\n",
    "\n",
    "            average_val_loss = val_loss / val_samples\n",
    "\n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            val_losses.append(average_val_loss)\n",
    "            item_train_losses.append(running_loss / len(train_loader))\n",
    "            item_val_losses.append(average_val_loss)\n",
    "\n",
    "            epoch_numbers.append(epoch + 1)\n",
    "            print('Epoch %d - Training Loss: %.6f - Validation Loss: %.6f - Learning Rate: %.3f' % (epoch + 1, running_loss / len(train_loader), average_val_loss, learning_rate))\n",
    "\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f'trained_model_{item}.pt')\n",
    "\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print('No improvement in validation loss. Early stopping.')\n",
    "                break\n",
    "\n",
    "        print('Epoch %d completed.' % (epoch + 1))\n",
    "\n",
    "    best_train_loss = min(item_train_losses)\n",
    "    best_train_losses[item] = best_train_loss\n",
    "\n",
    "    best_val_loss = min(item_val_losses)\n",
    "    best_val_losses[item] = best_val_loss\n",
    "    # Plotting the losses\n",
    "    # epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epoch_numbers, train_losses, label='Training Loss')\n",
    "    plt.plot(epoch_numbers, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(f'loss_plot_{item}.jpeg', format='jpeg')\n",
    "\n",
    "\n",
    "   \n",
    "    # # Create a DataFrame to store the predictions\n",
    "    # predictions_df = pd.DataFrame(columns=['Image', 'Real Value', 'Predicted Value', 'Difference'])\n",
    "\n",
    "    # # Iterate over the figures in the folder\n",
    "    # for filename in os.listdir(image_folder):\n",
    "    #     if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust the file extensions as per your figures\n",
    "    #         image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "    #         # Load and preprocess the image\n",
    "    #         image = Image.open(image_path).convert('RGB')\n",
    "    #         input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "    #         # Extract the real value from the filename\n",
    "    #         real_value = int(filename.split('_')[1][1:])  # Adjust the splitting pattern to extract the desired value\n",
    "            \n",
    "    #         # Make the prediction\n",
    "    #         with torch.no_grad():\n",
    "    #             output = model(input_tensor)\n",
    "    #         predicted_value = output.item()\n",
    "            \n",
    "    #         # Calculate the difference between predicted and real value\n",
    "    #         difference = predicted_value - real_value\n",
    "\n",
    "    #         # Add the prediction, real value, and difference to the DataFrame\n",
    "    #         predictions_df = predictions_df.append({'Image': filename, 'Real Value': real_value, 'Predicted Value': predicted_value, 'Difference': difference}, ignore_index=True)\n",
    "\n",
    "    #     # # Print the predictions table\n",
    "    #     # print(predictions_df)\n",
    "\n",
    "    # Create a DataFrame to store the predictions\n",
    "    predictions_test_df = pd.DataFrame(columns=['Real Value', 'Predicted Value', 'Difference'])\n",
    "\n",
    "    model = CNN()  # Instantiate a new instance of the CNN class\n",
    "    model.load_state_dict(torch.load('trained_model_{item}'))  # Load the state dictionary of the pre-trained model\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables for tracking correct predictions and total samples\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Define the range for considering a prediction as correct\n",
    "    max_range = 0.5\n",
    "\n",
    "    # Iterate over the test data\n",
    "    for sample in test_loader:\n",
    "\n",
    "        # Move the input data to the device\n",
    "        inputs = sample[0].to(device)  # Assuming the input images are the first element in each sample\n",
    "        labels = sample[1].to(device)  # Assuming the labels are the second element in each sample\n",
    "\n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            predicted_values = model(inputs).squeeze().tolist()\n",
    "\n",
    "        # Get the predicted labels\n",
    "        predicted_labels = outputs  # Assuming the model output is a single scalar value\n",
    "\n",
    "        # Calculate the number of correct predictions within the range\n",
    "        # correct_predictions += ((predicted_labels >= min_range) & (predicted_labels <= max_range) & (labels >= min_range) & (labels <= max_range)).sum().item()\n",
    "        \n",
    "    # Iterate over the predicted values and add them to the DataFrame\n",
    "        for i in range(len(predicted_values)):\n",
    "            real_value = labels[i].item()\n",
    "            predicted_value = predicted_values[i]\n",
    "\n",
    "            # Check if the predicted value is within the desired range (40-70)\n",
    "            if real_value >= 40 and real_value <= 70:\n",
    "                # Calculate the difference between predicted and real value\n",
    "                difference = predicted_value - real_value\n",
    "\n",
    "                # Add the prediction, real value, and difference to the DataFrame\n",
    "                predictions_test_df = predictions_test_df.append({'Real Value': real_value, 'Predicted Value': predicted_value, 'Difference': difference}, ignore_index=True)\n",
    "\n",
    "                # Check if the prediction is correct within the desired range\n",
    "                if abs(real_value - predicted_value) <= max_range:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy_value = correct_predictions / (len(predictions_test_df)-1)\n",
    "    accuracy.append(accuracy_value)\n",
    "\n",
    "    # # Print the predictions DataFrame\n",
    "    # print(predictions_test_df)\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f\"Accuracy for {item}: {accuracy_value * 100:.2f}%\")\n",
    "    \n",
    "for item in sets:\n",
    "    print(f\"Item: {item}\")\n",
    "    print(f\"Best Validation Loss: {best_val_losses[item]}\")\n",
    "    print(f\"Best Training Loss: {best_train_losses[item]}\")\n",
    "    print(f\"Accuracy for {item}: {accuracy_value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Train_510\n",
      "Best Validation Loss: 213.3171792123832\n",
      "Best Training Loss: 344.830419921875\n",
      "Accuracy for Train_510: 0.00%\n",
      "Item: Train_1020\n",
      "Best Validation Loss: 2.5618433928957174\n",
      "Best Training Loss: 65.54328365325928\n",
      "Accuracy for Train_1020: 3.15%\n",
      "Item: Train_2040\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Train_2040'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-9cca8083b397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Item: {item}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best Validation Loss: {best_val_losses[item]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best Training Loss: {best_train_losses[item]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy for {item}: {accuracy[i] * 100:.2f}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Train_2040'"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(sets):\n",
    "    print(f\"Item: {item}\")\n",
    "    print(f\"Best Validation Loss: {best_val_losses[item]}\")\n",
    "    print(f\"Best Training Loss: {best_train_losses[item]}\")\n",
    "    print(f\"Accuracy for {item}: {accuracy[i] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-2026af660b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# sets = ['Train_510', 'Train_1020', 'Train_2040', 'Train_4080', 'Train_8160', 'Train_10200']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data set size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2888\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m         edgecolors=None, *, plotnonfinite=False, data=None, **kwargs):\n\u001b[1;32m-> 2890\u001b[1;33m     __ret = gca().scatter(\n\u001b[0m\u001b[0;32m   2891\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2892\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                 **kwargs)\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4439\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4441\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(sets, accuracy)\n",
    "plt.xlabel('Data set size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Different Sets')\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Train_2040'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-c8f7856f0a4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare data for scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_val_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_val_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_train_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-125-c8f7856f0a4c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare data for scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_val_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_val_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_train_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Train_2040'"
     ]
    }
   ],
   "source": [
    "# Prepare data for scatter plot\n",
    "x_values = sets\n",
    "y_val_losses = [best_val_losses[item] for item in sets]\n",
    "y_train_losses = [best_train_losses[item] for item in sets]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(x_values, y_val_losses, label='Best Validation Loss')\n",
    "plt.scatter(x_values, y_train_losses, label='Best Training Loss')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Sets')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Best Validation and Training Loss per set')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('Best_losses_per_set.jpeg', format='jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
