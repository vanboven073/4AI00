{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device for computation (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): # results in accuracy of 73.22%\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        x = self.leaky_relu(self.fc3(x))\n",
    "        x = self.leaky_relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module): # OVERFITS\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.conv6 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "#         self.conv7 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)  # Additional layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(1024 * 2 * 2, 1024)  # Updated input size\n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, 256)\n",
    "#         self.fc4 = nn.Linear(256, 128)\n",
    "#         self.fc5 = nn.Linear(128, 64)  # New layer with 64 output neurons\n",
    "#         self.fc6 = nn.Linear(64, 1)  # Additional layer with 1 output neuron\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv6(x)))\n",
    "#         x = self.leaky_relu(self.conv7(x))  # Additional layer\n",
    "#         x = x.view(-1, 1024 * 2 * 2)  # Reshape the tensor\n",
    "#         x = self.leaky_relu(self.fc1(x))\n",
    "#         x = self.leaky_relu(self.fc2(x))\n",
    "#         x = self.leaky_relu(self.fc3(x))\n",
    "#         x = self.leaky_relu(self.fc4(x))\n",
    "#         x = self.leaky_relu(self.fc5(x))  # Apply activation to new layer\n",
    "#         x = self.fc6(x)  # Pass through additional layer\n",
    "#         return x.squeeze(1)  # Squeeze the output tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(512 * 2 * 2, 2048)\n",
    "#         self.fc2 = nn.Linear(2048, 1024)\n",
    "#         self.fc3 = nn.Linear(1024, 512)\n",
    "#         self.fc4 = nn.Linear(512, 256)\n",
    "#         self.fc5 = nn.Linear(256, 1)\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "#         x = x.view(-1, 512 * 2 * 2)\n",
    "#         x = self.leaky_relu(self.fc1(x))\n",
    "#         x = self.leaky_relu(self.fc2(x))\n",
    "#         x = self.leaky_relu(self.fc3(x))\n",
    "#         x = self.leaky_relu(self.fc4(x))\n",
    "#         x = self.fc5(x)\n",
    "#         return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 2672.886774 - Validation Loss: 522.886952 - Learning Rate: 0.001\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Training Loss: 631.304401 - Validation Loss: 231.671557 - Learning Rate: 0.001\n",
      "Epoch 2 completed.\n",
      "Epoch 3 - Training Loss: 431.246295 - Validation Loss: 229.455297 - Learning Rate: 0.001\n",
      "Epoch 3 completed.\n",
      "Epoch 4 - Training Loss: 410.076965 - Validation Loss: 252.410338 - Learning Rate: 0.001\n",
      "Epoch 4 completed.\n",
      "Epoch 5 - Training Loss: 409.282617 - Validation Loss: 281.125330 - Learning Rate: 0.001\n",
      "Epoch 5 completed.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Train_510: 6.67%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-b4d85e07a214>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-169-b4d85e07a214>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RGB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    902\u001b[0m         \"\"\"\n\u001b[0;32m    903\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create training dataset\n",
    "# Set up the data directories\n",
    "sets = ['Train_510', 'Train_1020', 'Train_2040', 'Train_4080', 'Train_8160', 'Train_10200']\n",
    "best_train_losses = {}  # Dictionary to store the best training loss for each item\n",
    "best_val_losses = {}  # Dictionary to store the best validation loss for each item\n",
    "accuracy = []\n",
    "for item in sets:\n",
    "    data_dir = 'Test_Images'\n",
    "    train_dir = os.path.join(data_dir, item)\n",
    "\n",
    "    # Define a function to get the labels from the image filenames\n",
    "    def get_label(filename):\n",
    "        match = re.search(r'\\d+\\.?\\d*', filename)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Define a list to store the image filenames and labels\n",
    "    train_data = []\n",
    "\n",
    "    # Iterate over the training images and add them to the list\n",
    "    for filename in os.listdir(train_dir):\n",
    "        label = get_label(filename)\n",
    "        if label is not None:\n",
    "            train_data.append([os.path.join(train_dir, filename), label])\n",
    "\n",
    "    # Convert the list to a dataframe\n",
    "    train_df = pd.DataFrame(train_data, columns=['filename', 'label'])\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    train_df.to_csv(os.path.join(data_dir, item+'.csv'), index=False)\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = self._load_data(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_data(self, csv_file):\n",
    "        data = []\n",
    "        with open(csv_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines[1:]:\n",
    "                image_path, label = line.strip().split(',')\n",
    "                data.append((image_path, float(label)))\n",
    "        return data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.4753, 0.4753, 0.4753])\n",
    "])\n",
    "\n",
    "for item in sets:\n",
    "    csv_file = f'Test_Images/{item}.csv'\n",
    "    image_folder = f'Test_Images/{item}'\n",
    "\n",
    "    dataset = CustomImageDataset(csv_file, image_folder, transform=transform)\n",
    "\n",
    "    train_size = int(0.6 * len(dataset))\n",
    "    val_size = int(0.2 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    num_epochs = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_learning_rate = None\n",
    "    patience = 5\n",
    "    counter = 0\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_numbers = []\n",
    "    item_train_losses = []  # List to store training losses for the current item\n",
    "    item_val_losses = []  # List to store validation losses for the current item\n",
    "\n",
    "    model = CNN()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "\n",
    "            l1_lambda = 0.01\n",
    "            l1_regularization = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l1_regularization += torch.norm(param, 1)\n",
    "            loss += l1_lambda * l1_regularization\n",
    "\n",
    "            l2_lambda = 0.01\n",
    "            l2_regularization = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l2_regularization += torch.norm(param, 2)\n",
    "            loss += l2_lambda * l2_regularization\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            val_samples = 0\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_samples += inputs.size(0)\n",
    "\n",
    "            average_val_loss = val_loss / val_samples\n",
    "\n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            val_losses.append(average_val_loss)\n",
    "            item_train_losses.append(running_loss / len(train_loader))\n",
    "            item_val_losses.append(average_val_loss)\n",
    "\n",
    "            epoch_numbers.append(epoch + 1)\n",
    "            print('Epoch %d - Training Loss: %.6f - Validation Loss: %.6f - Learning Rate: %.3f' % (epoch + 1, running_loss / len(train_loader), average_val_loss, learning_rate))\n",
    "\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f'trained_model_{item}.pt')\n",
    "\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print('No improvement in validation loss. Early stopping.')\n",
    "                break\n",
    "\n",
    "        print('Epoch %d completed.' % (epoch + 1))\n",
    "\n",
    "    best_train_loss = min(item_train_losses)\n",
    "    best_train_losses[item] = best_train_loss\n",
    "\n",
    "    best_val_loss = min(item_val_losses)\n",
    "    best_val_losses[item] = best_val_loss\n",
    "    # Plotting the losses\n",
    "    # epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epoch_numbers, train_losses, label='Training Loss')\n",
    "    plt.plot(epoch_numbers, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig(f'loss_plot_{item}.jpeg', format='jpeg')\n",
    "\n",
    "\n",
    "   \n",
    "    # # Create a DataFrame to store the predictions\n",
    "    # predictions_df = pd.DataFrame(columns=['Image', 'Real Value', 'Predicted Value', 'Difference'])\n",
    "\n",
    "    # # Iterate over the figures in the folder\n",
    "    # for filename in os.listdir(image_folder):\n",
    "    #     if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust the file extensions as per your figures\n",
    "    #         image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "    #         # Load and preprocess the image\n",
    "    #         image = Image.open(image_path).convert('RGB')\n",
    "    #         input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "    #         # Extract the real value from the filename\n",
    "    #         real_value = int(filename.split('_')[1][1:])  # Adjust the splitting pattern to extract the desired value\n",
    "            \n",
    "    #         # Make the prediction\n",
    "    #         with torch.no_grad():\n",
    "    #             output = model(input_tensor)\n",
    "    #         predicted_value = output.item()\n",
    "            \n",
    "    #         # Calculate the difference between predicted and real value\n",
    "    #         difference = predicted_value - real_value\n",
    "\n",
    "    #         # Add the prediction, real value, and difference to the DataFrame\n",
    "    #         predictions_df = predictions_df.append({'Image': filename, 'Real Value': real_value, 'Predicted Value': predicted_value, 'Difference': difference}, ignore_index=True)\n",
    "\n",
    "    #     # # Print the predictions table\n",
    "    #     # print(predictions_df)\n",
    "\n",
    "    # Create a DataFrame to store the predictions\n",
    "    predictions_test_df = pd.DataFrame(columns=['Real Value', 'Predicted Value', 'Difference'])\n",
    "\n",
    "    model = CNN()  # Instantiate a new instance of the CNN class\n",
    "    model.load_state_dict(torch.load(f'trained_model_{item}.pt'))  # Load the state dictionary of the pre-trained model\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables for tracking correct predictions and total samples\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Define the range for considering a prediction as correct\n",
    "    max_range = 0.5\n",
    "\n",
    "    # Iterate over the test data\n",
    "    for sample in test_loader:\n",
    "\n",
    "        # Move the input data to the device\n",
    "        inputs = sample[0].to(device)  # Assuming the input images are the first element in each sample\n",
    "        labels = sample[1].to(device)  # Assuming the labels are the second element in each sample\n",
    "\n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            predicted_values = model(inputs).squeeze().tolist()\n",
    "\n",
    "        # Get the predicted labels\n",
    "        predicted_labels = outputs  # Assuming the model output is a single scalar value\n",
    "\n",
    "        # Calculate the number of correct predictions within the range\n",
    "        # correct_predictions += ((predicted_labels >= min_range) & (predicted_labels <= max_range) & (labels >= min_range) & (labels <= max_range)).sum().item()\n",
    "        \n",
    "    # Iterate over the predicted values and add them to the DataFrame\n",
    "        for i in range(len(predicted_values)):\n",
    "            real_value = labels[i].item()\n",
    "            predicted_value = predicted_values[i]\n",
    "\n",
    "            # Check if the predicted value is within the desired range (40-70)\n",
    "            if real_value >= 40 and real_value <= 70:\n",
    "                # Calculate the difference between predicted and real value\n",
    "                difference = predicted_value - real_value\n",
    "\n",
    "                # Add the prediction, real value, and difference to the DataFrame\n",
    "                predictions_test_df = predictions_test_df.append({'Real Value': real_value, 'Predicted Value': predicted_value, 'Difference': difference}, ignore_index=True)\n",
    "\n",
    "                # Check if the prediction is correct within the desired range\n",
    "                if abs(real_value - predicted_value) <= max_range:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy_value = correct_predictions / (len(predictions_test_df)-1)\n",
    "    accuracy.append(accuracy_value)\n",
    "\n",
    "    # # Print the predictions DataFrame\n",
    "    # print(predictions_test_df)\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f\"Accuracy for {item}: {accuracy_value * 100:.2f}%\")\n",
    "    \n",
    "for item in sets:\n",
    "    print(f\"Item: {item}\")\n",
    "    print(f\"Best Validation Loss: {best_val_losses[item]}\")\n",
    "    print(f\"Best Training Loss: {best_train_losses[item]}\")\n",
    "    print(f\"Accuracy for {item}: {accuracy_value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Train_510\n",
      "Best Validation Loss: 213.3171792123832\n",
      "Best Training Loss: 344.830419921875\n",
      "Accuracy for Train_510: 0.00%\n",
      "Item: Train_1020\n",
      "Best Validation Loss: 2.5618433928957174\n",
      "Best Training Loss: 65.54328365325928\n",
      "Accuracy for Train_1020: 3.15%\n",
      "Item: Train_2040\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Train_2040'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-9cca8083b397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Item: {item}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best Validation Loss: {best_val_losses[item]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best Training Loss: {best_train_losses[item]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy for {item}: {accuracy[i] * 100:.2f}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Train_2040'"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(sets):\n",
    "    print(f\"Item: {item}\")\n",
    "    print(f\"Best Validation Loss: {best_val_losses[item]}\")\n",
    "    print(f\"Best Training Loss: {best_train_losses[item]}\")\n",
    "    print(f\"Accuracy for {item}: {accuracy[i] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-2026af660b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# sets = ['Train_510', 'Train_1020', 'Train_2040', 'Train_4080', 'Train_8160', 'Train_10200']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data set size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2888\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m         edgecolors=None, *, plotnonfinite=False, data=None, **kwargs):\n\u001b[1;32m-> 2890\u001b[1;33m     __ret = gca().scatter(\n\u001b[0m\u001b[0;32m   2891\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2892\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                 **kwargs)\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4439\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4441\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(sets, accuracy)\n",
    "plt.xlabel('Data set size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Different Sets')\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels if needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Train_2040'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-c8f7856f0a4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare data for scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_val_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_val_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_train_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-125-c8f7856f0a4c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare data for scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_val_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_val_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_train_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Train_2040'"
     ]
    }
   ],
   "source": [
    "# Prepare data for scatter plot\n",
    "x_values = sets\n",
    "y_val_losses = [best_val_losses[item] for item in sets]\n",
    "y_train_losses = [best_train_losses[item] for item in sets]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(x_values, y_val_losses, label='Best Validation Loss')\n",
    "plt.scatter(x_values, y_train_losses, label='Best Training Loss')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Sets')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Best Validation and Training Loss per set')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('Best_losses_per_set.jpeg', format='jpeg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
