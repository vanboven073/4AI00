{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Normalize\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device for computation (CPU or GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module): # results in accuracy of 73.22%\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(256 * 2 * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "        x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "        x = x.view(-1, 256 * 2 * 2)\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        x = self.leaky_relu(self.fc2(x))\n",
    "        x = self.leaky_relu(self.fc3(x))\n",
    "        x = self.leaky_relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module): # OVERFITS\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.conv6 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "#         self.conv7 = nn.Conv2d(512, 1024, kernel_size=3, padding=1)  # Additional layer\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(1024 * 2 * 2, 1024)  # Updated input size\n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, 256)\n",
    "#         self.fc4 = nn.Linear(256, 128)\n",
    "#         self.fc5 = nn.Linear(128, 64)  # New layer with 64 output neurons\n",
    "#         self.fc6 = nn.Linear(64, 1)  # Additional layer with 1 output neuron\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv6(x)))\n",
    "#         x = self.leaky_relu(self.conv7(x))  # Additional layer\n",
    "#         x = x.view(-1, 1024 * 2 * 2)  # Reshape the tensor\n",
    "#         x = self.leaky_relu(self.fc1(x))\n",
    "#         x = self.leaky_relu(self.fc2(x))\n",
    "#         x = self.leaky_relu(self.fc3(x))\n",
    "#         x = self.leaky_relu(self.fc4(x))\n",
    "#         x = self.leaky_relu(self.fc5(x))  # Apply activation to new layer\n",
    "#         x = self.fc6(x)  # Pass through additional layer\n",
    "#         return x.squeeze(1)  # Squeeze the output tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "#         self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(512 * 2 * 2, 2048)\n",
    "#         self.fc2 = nn.Linear(2048, 1024)\n",
    "#         self.fc3 = nn.Linear(1024, 512)\n",
    "#         self.fc4 = nn.Linear(512, 256)\n",
    "#         self.fc5 = nn.Linear(256, 1)\n",
    "#         self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(self.leaky_relu(self.conv1(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv2(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv3(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv4(x)))\n",
    "#         x = self.pool(self.leaky_relu(self.conv5(x)))\n",
    "#         x = x.view(-1, 512 * 2 * 2)\n",
    "#         x = self.leaky_relu(self.fc1(x))\n",
    "#         x = self.leaky_relu(self.fc2(x))\n",
    "#         x = self.leaky_relu(self.fc3(x))\n",
    "#         x = self.leaky_relu(self.fc4(x))\n",
    "#         x = self.fc5(x)\n",
    "#         return x.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training Loss: 2718.872577 - Validation Loss: 374.650687 - Learning Rate: 0.001\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Training Loss: 606.262485 - Validation Loss: 246.652382 - Learning Rate: 0.001\n",
      "Epoch 2 completed.\n",
      "Epoch 3 - Training Loss: 471.165048 - Validation Loss: 391.409679 - Learning Rate: 0.001\n",
      "Epoch 3 completed.\n",
      "Epoch 4 - Training Loss: 483.007901 - Validation Loss: 259.904299 - Learning Rate: 0.001\n",
      "Epoch 4 completed.\n",
      "Epoch 5 - Training Loss: 419.007678 - Validation Loss: 232.167020 - Learning Rate: 0.001\n",
      "Epoch 5 completed.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Train_510: 1.75%\n",
      "Epoch 1 - Training Loss: 2676.869980 - Validation Loss: 1707.244440 - Learning Rate: 0.001\n",
      "Epoch 1 completed.\n",
      "Epoch 2 - Training Loss: 753.206003 - Validation Loss: 234.425091 - Learning Rate: 0.001\n",
      "Epoch 2 completed.\n",
      "Epoch 3 - Training Loss: 452.451132 - Validation Loss: 228.882632 - Learning Rate: 0.001\n",
      "Epoch 3 completed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-200-bf135c0c4315>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-197-2921596abb8d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 459\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create training dataset\n",
    "# Set up the data directories\n",
    "sets = ['Train_510', 'Train_1020', 'Train_2040', 'Train_4080', 'Train_8160', 'Train_10200']\n",
    "best_train_losses = {}  # Dictionary to store the best training loss for each item\n",
    "best_val_losses = {}  # Dictionary to store the best validation loss for each item\n",
    "accuracy = []\n",
    "for item in sets:\n",
    "    data_dir = 'Test_Images'\n",
    "    train_dir = os.path.join(data_dir, item)\n",
    "\n",
    "    # Define a function to get the labels from the image filenames\n",
    "    def get_label(filename):\n",
    "        match = re.search(r'\\d+\\.?\\d*', filename)\n",
    "        if match:\n",
    "            return float(match.group())\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Define a list to store the image filenames and labels\n",
    "    train_data = []\n",
    "\n",
    "    # Iterate over the training images and add them to the list\n",
    "    for filename in os.listdir(train_dir):\n",
    "        label = get_label(filename)\n",
    "        if label is not None:\n",
    "            train_data.append([os.path.join(train_dir, filename), label])\n",
    "\n",
    "    # Convert the list to a dataframe\n",
    "    train_df = pd.DataFrame(train_data, columns=['filename', 'label'])\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    train_df.to_csv(os.path.join(data_dir, item+'.csv'), index=False)\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = self._load_data(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def _load_data(self, csv_file):\n",
    "        data = []\n",
    "        with open(csv_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines[1:]:\n",
    "                image_path, label = line.strip().split(',')\n",
    "                data.append((image_path, float(label)))\n",
    "        return data\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.4753, 0.4753, 0.4753])\n",
    "])\n",
    "\n",
    "for item in sets:\n",
    "    csv_file = f'Test_Images/{item}.csv'\n",
    "    image_folder = f'Test_Images/{item}'\n",
    "\n",
    "    dataset = CustomImageDataset(csv_file, image_folder, transform=transform)\n",
    "\n",
    "    train_size = int(0.6 * len(dataset))\n",
    "    val_size = int(0.2 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    num_epochs = 5\n",
    "    best_val_loss = float('inf')\n",
    "    best_learning_rate = None\n",
    "    patience = 5\n",
    "    counter = 0\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    epoch_numbers = []\n",
    "    item_train_losses = []  # List to store training losses for the current item\n",
    "    item_val_losses = []  # List to store validation losses for the current item\n",
    "\n",
    "    model = CNN()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "\n",
    "            l1_lambda = 0.01\n",
    "            l1_regularization = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l1_regularization += torch.norm(param, 1)\n",
    "            loss += l1_lambda * l1_regularization\n",
    "\n",
    "            l2_lambda = 0.01\n",
    "            l2_regularization = torch.tensor(0.)\n",
    "            for param in model.parameters():\n",
    "                l2_regularization += torch.norm(param, 2)\n",
    "            loss += l2_lambda * l2_regularization\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.6f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            val_samples = 0\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                val_samples += inputs.size(0)\n",
    "\n",
    "            average_val_loss = val_loss / val_samples\n",
    "\n",
    "            train_losses.append(running_loss / len(train_loader))\n",
    "            val_losses.append(average_val_loss)\n",
    "            item_train_losses.append(running_loss / len(train_loader))\n",
    "            item_val_losses.append(average_val_loss)\n",
    "\n",
    "            epoch_numbers.append(epoch + 1)\n",
    "            print('Epoch %d - Training Loss: %.6f - Validation Loss: %.6f - Learning Rate: %.3f' % (epoch + 1, running_loss / len(train_loader), average_val_loss, learning_rate))\n",
    "\n",
    "        if average_val_loss < best_val_loss:\n",
    "            best_val_loss = average_val_loss\n",
    "            counter = 0\n",
    "            torch.save(model.state_dict(), f'trained_model_{item}.pt')\n",
    "\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print('No improvement in validation loss. Early stopping.')\n",
    "                break\n",
    "\n",
    "        print('Epoch %d completed.' % (epoch + 1))\n",
    "\n",
    "    best_train_loss = min(item_train_losses)\n",
    "    best_train_losses[item] = best_train_loss\n",
    "\n",
    "    best_val_loss = min(item_val_losses)\n",
    "    best_val_losses[item] = best_val_loss\n",
    "    # Plotting the losses\n",
    "    # epochs = range(1, num_epochs + 1)\n",
    "    plt.plot(epoch_numbers, train_losses, label='Training Loss')\n",
    "    plt.plot(epoch_numbers, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'loss_plot_{item}.jpeg', format='jpeg')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "   \n",
    "    # # Create a DataFrame to store the predictions\n",
    "    # predictions_df = pd.DataFrame(columns=['Image', 'Real Value', 'Predicted Value', 'Difference'])\n",
    "\n",
    "    # # Iterate over the figures in the folder\n",
    "    # for filename in os.listdir(image_folder):\n",
    "    #     if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust the file extensions as per your figures\n",
    "    #         image_path = os.path.join(image_folder, filename)\n",
    "            \n",
    "    #         # Load and preprocess the image\n",
    "    #         image = Image.open(image_path).convert('RGB')\n",
    "    #         input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "            \n",
    "    #         # Extract the real value from the filename\n",
    "    #         real_value = int(filename.split('_')[1][1:])  # Adjust the splitting pattern to extract the desired value\n",
    "            \n",
    "    #         # Make the prediction\n",
    "    #         with torch.no_grad():\n",
    "    #             output = model(input_tensor)\n",
    "    #         predicted_value = output.item()\n",
    "            \n",
    "    #         # Calculate the difference between predicted and real value\n",
    "    #         difference = predicted_value - real_value\n",
    "\n",
    "    #         # Add the prediction, real value, and difference to the DataFrame\n",
    "    #         predictions_df = predictions_df.append({'Image': filename, 'Real Value': real_value, 'Predicted Value': predicted_value, 'Difference': difference}, ignore_index=True)\n",
    "\n",
    "    #     # # Print the predictions table\n",
    "    #     # print(predictions_df)\n",
    "\n",
    "    # Create a DataFrame to store the predictions\n",
    "    predictions_test_df = pd.DataFrame(columns=['Real Value', 'Predicted Value', 'Difference'])\n",
    "\n",
    "    model = CNN()  # Instantiate a new instance of the CNN class\n",
    "    model.load_state_dict(torch.load(f'trained_model_{item}.pt'))  # Load the state dictionary of the pre-trained model\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize variables for tracking correct predictions and total samples\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Define the range for considering a prediction as correct\n",
    "    max_range = 0.5\n",
    "\n",
    "    # Iterate over the test data\n",
    "    for sample in test_loader:\n",
    "\n",
    "        # Move the input data to the device\n",
    "        inputs = sample[0].to(device)  # Assuming the input images are the first element in each sample\n",
    "        labels = sample[1].to(device)  # Assuming the labels are the second element in each sample\n",
    "\n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            predicted_values = model(inputs).squeeze().tolist()\n",
    "\n",
    "        # Get the predicted labels\n",
    "        predicted_labels = outputs  # Assuming the model output is a single scalar value\n",
    "\n",
    "        # Calculate the number of correct predictions within the range\n",
    "        # correct_predictions += ((predicted_labels >= min_range) & (predicted_labels <= max_range) & (labels >= min_range) & (labels <= max_range)).sum().item()\n",
    "        \n",
    "    # Iterate over the predicted values and add them to the DataFrame\n",
    "        for i in range(len(predicted_values)):\n",
    "            real_value = labels[i].item()\n",
    "            predicted_value = predicted_values[i]\n",
    "\n",
    "            # Check if the predicted value is within the desired range (40-70)\n",
    "            if real_value >= 40 and real_value <= 70:\n",
    "                # Calculate the difference between predicted and real value\n",
    "                difference = predicted_value - real_value\n",
    "\n",
    "                # Add the prediction, real value, and difference to the DataFrame\n",
    "                predictions_test_df = predictions_test_df.append({'Real Value': real_value, 'Predicted Value': predicted_value, 'Difference': difference}, ignore_index=True)\n",
    "\n",
    "                # Check if the prediction is correct within the desired range\n",
    "                if abs(real_value - predicted_value) <= max_range:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    accuracy_value = correct_predictions / (len(predictions_test_df)-1)\n",
    "    accuracy.append(accuracy_value)\n",
    "\n",
    "    # # Print the predictions DataFrame\n",
    "    # print(predictions_test_df)\n",
    "\n",
    "    # Print the accuracy\n",
    "    print(f\"Accuracy for {item}: {accuracy_value * 100:.2f}%\")\n",
    "    \n",
    "for item in sets:\n",
    "    print(f\"Item: {item}\")\n",
    "    print(f\"Best Validation Loss: {best_val_losses[item]}\")\n",
    "    print(f\"Best Training Loss: {best_train_losses[item]}\")\n",
    "    print(f\"Accuracy for {item}: {accuracy_value * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item: Train_510\n",
      "Best Validation Loss: 213.3171792123832\n",
      "Best Training Loss: 344.830419921875\n",
      "Accuracy for Train_510: 0.00%\n",
      "Item: Train_1020\n",
      "Best Validation Loss: 2.5618433928957174\n",
      "Best Training Loss: 65.54328365325928\n",
      "Accuracy for Train_1020: 3.15%\n",
      "Item: Train_2040\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Train_2040'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-9cca8083b397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Item: {item}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best Validation Loss: {best_val_losses[item]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Best Training Loss: {best_train_losses[item]}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Accuracy for {item}: {accuracy[i] * 100:.2f}%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Train_2040'"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(sets):\n",
    "    print(f\"Item: {item}\")\n",
    "    print(f\"Best Validation Loss: {best_val_losses[item]}\")\n",
    "    print(f\"Best Training Loss: {best_train_losses[item]}\")\n",
    "    print(f\"Accuracy for {item}: {accuracy[i] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-2026af660b89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# sets = ['Train_510', 'Train_1020', 'Train_2040', 'Train_4080', 'Train_8160', 'Train_10200']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data set size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2888\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deprecated_parameter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2889\u001b[0m         edgecolors=None, *, plotnonfinite=False, data=None, **kwargs):\n\u001b[1;32m-> 2890\u001b[1;33m     __ret = gca().scatter(\n\u001b[0m\u001b[0;32m   2891\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2892\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1447\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    409\u001b[0m                          \u001b[1;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                 **kwargs)\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4439\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4441\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(sets, accuracy)\n",
    "plt.xlabel('Data set size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Different Sets')\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels if needed\n",
    "plt.savefig('Accuracy per data set.jpeg', format='jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Train_2040'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-3d025d43b9f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare data for scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_val_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_val_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_train_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-176-3d025d43b9f1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Prepare data for scatter plot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_val_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_val_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbest_train_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Train_2040'"
     ]
    }
   ],
   "source": [
    "# Prepare data for scatter plot\n",
    "x_values = sets\n",
    "y_val_losses = [best_val_losses[item] for item in sets]\n",
    "y_train_losses = [best_train_losses[item] for item in sets]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.scatter(x_values, y_val_losses, label='Best Validation Loss')\n",
    "plt.scatter(x_values, y_train_losses, label='Best Training Loss')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Sets')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Best Validation and Training Loss per set')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('Best_losses_per_set.jpeg', format='jpeg')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
